%%
% Copyright (c) 2017 - 2025, Pascal Wagler;
% Copyright (c) 2014 - 2025, John MacFarlane
%
% All rights reserved.
%
% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions
% are met:
%
% - Redistributions of source code must retain the above copyright
% notice, this list of conditions and the following disclaimer.
%
% - Redistributions in binary form must reproduce the above copyright
% notice, this list of conditions and the following disclaimer in the
% documentation and/or other materials provided with the distribution.
%
% - Neither the name of John MacFarlane nor the names of other
% contributors may be used to endorse or promote products derived
% from this software without specific prior written permission.
%
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
% "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
% LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
% FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
% COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
% INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
% BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
% LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
% CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
% LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
% ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
% POSSIBILITY OF SUCH DAMAGE.
%%

%%
% This is the Eisvogel pandoc LaTeX template.
%
% For usage information and examples visit the official GitHub page:
% https://github.com/Wandmalfarbe/pandoc-latex-template
%%
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names,table}{xcolor}
\documentclass[
  american,
  11pt,
  letterpaper,
  oneside  ,captions=tableheading
]{scrartcl}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}

% add backlinks to footnote references, cf. https://tex.stackexchange.com/questions/302266/make-footnote-clickable-both-ways
\usepackage{footnotebackref}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[]{DejaVu Serif}
  \setsansfont[]{DejaVu Sans}
  \setmonofont[]{DejaVu Sans Mono}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}

\usepackage{setspace}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\lstset{defaultdialect=[5.3]Lua}
\lstset{defaultdialect=[x86masm]Assembler}
\usepackage{etoolbox}
\BeforeBeginEnvironment{lstlisting}{\par\noindent\begin{minipage}{\linewidth}}
\AfterEndEnvironment{lstlisting}{\end{minipage}\par\addvspace{\topskip}}
\usepackage{longtable,booktabs,array}
\newcounter{none} % for unnumbered tables
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
\usepackage[bidi=basic,shorthands=off]{babel}
\else
\usepackage[bidi=default,shorthands=off]{babel}
\fi
\ifPDFTeX
\else
\babelfont{rm}[]{DejaVu Serif}
\fi
\ifLuaTeX
  \usepackage{selnolig} % disable illegal ligatures
\fi
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{graphicx}
\usepackage{xurl}
\usepackage{rotating}
\usepackage{booktabs}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\definecolor{default-linkcolor}{HTML}{A50000}
\definecolor{default-filecolor}{HTML}{A50000}
\definecolor{default-citecolor}{HTML}{4077C0}
\definecolor{default-urlcolor}{HTML}{4077C0}

\hypersetup{
  pdftitle={Healthcare Analytics Challenges: A Three-Pillar Framework Connecting Analytics Maturity, Workforce Dynamics, and Technical Barriers},
  pdfauthor={Samuel T Harrold, Yuimedi},
  pdflang={en-US},
  pdfkeywords={healthcare analytics, healthcare informatics, analytical
framework, analytics maturity, workforce turnover, institutional
memory, text-to-SQL, natural language processing, knowledge
portal, conversational AI},
  colorlinks=true,
  linkcolor={blue},
  filecolor={default-filecolor},
  citecolor={blue},
  urlcolor={blue},
  breaklinks=true,
  pdfcreator={LaTeX via pandoc with the Eisvogel template}}

\title{Healthcare Analytics Challenges: A Three-Pillar Framework
Connecting Analytics Maturity, Workforce Dynamics, and Technical
Barriers}
\author{Samuel T Harrold, Yuimedi}
\date{January 2026}


%
% for the background color of the title page
%
\usepackage{pagecolor}
\usepackage{afterpage}

%
% break urls
%
\PassOptionsToPackage{hyphens}{url}

%
% When using babel or polyglossia with biblatex, loading csquotes is recommended
% to ensure that quoted texts are typeset according to the rules of your main language.
%
\usepackage{csquotes}

%
% captions
%
\definecolor{caption-color}{HTML}{777777}
\usepackage[font={stretch=1.2}, textfont={color=caption-color}, position=top, skip=4mm, labelfont=bf, singlelinecheck=false, justification=raggedright]{caption}
\setcapindent{0em}

%
% blockquote
%
\definecolor{blockquote-border}{RGB}{221,221,221}
\definecolor{blockquote-text}{RGB}{119,119,119}
\usepackage{mdframed}
\newmdenv[rightline=false,bottomline=false,topline=false,linewidth=3pt,linecolor=blockquote-border,skipabove=\parskip]{customblockquote}
\renewenvironment{quote}{\begin{customblockquote}\list{}{\rightmargin=0em\leftmargin=0em}%
\item\relax\color{blockquote-text}\ignorespaces}{\unskip\unskip\endlist\end{customblockquote}}

%
% Source Sans Pro as the default font family
% Source Code Pro for monospace text
%
% 'default' option sets the default
% font family to Source Sans Pro, not \sfdefault.
%
% Note that the font has been officially renamed to `Source Sans 3`, and
% the version provided by the `sourcesanspro` package is slightly outdated.
% You can install the newer version locally and use it, for example, with
% `mainfont: "Source Sans 3"` in the YAML metadata (requires XeTeX or LuaTeX).
%
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
    \usepackage[default]{sourcesanspro}
  \usepackage{sourcecodepro}
  \else % if not pdftex
    \fi

%
% heading color
%
\definecolor{heading-color}{RGB}{40,40,40}
% By default, the KOMA-Script classes will typeset sectioning headings in
% sans-serif. Use the normal body font for headings.
\addtokomafont{disposition}{\normalfont\color{heading-color}\bfseries}

%
% variables for title, author and date
%
\usepackage{titling}
\title{Healthcare Analytics Challenges: A Three-Pillar Framework
Connecting Analytics Maturity, Workforce Dynamics, and Technical
Barriers}
\author{Samuel T Harrold, Yuimedi}
\date{January 2026}

%
% tables
%

\definecolor{table-row-color}{HTML}{F5F5F5}
\definecolor{table-rule-color}{HTML}{999999}

%\arrayrulecolor{black!40}
\arrayrulecolor{table-rule-color}     % color of \toprule, \midrule, \bottomrule
\setlength\heavyrulewidth{0.3ex}      % thickness of \toprule, \bottomrule
\renewcommand{\arraystretch}{1.3}     % spacing (padding)


%
% remove paragraph indentation
%
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines

%
%
% Listings
%
%


%
% general listing colors
%
\definecolor{listing-background}{HTML}{F7F7F7}
\definecolor{listing-rule}{HTML}{B3B2B3}
\definecolor{listing-numbers}{HTML}{B3B2B3}
\definecolor{listing-text-color}{HTML}{000000}
\definecolor{listing-keyword}{HTML}{435489}
\definecolor{listing-keyword-2}{HTML}{1284CA} % additional keywords
\definecolor{listing-keyword-3}{HTML}{9137CB} % additional keywords
\definecolor{listing-identifier}{HTML}{435489}
\definecolor{listing-string}{HTML}{00999A}
\definecolor{listing-comment}{HTML}{8E8E8E}

\lstdefinestyle{eisvogel_listing_style}{
  language         = java,
  numbers          = left,
  xleftmargin      = 2.7em,
  framexleftmargin = 2.5em,
  backgroundcolor  = \color{listing-background},
  basicstyle       = \color{listing-text-color}\linespread{1.0}%
                      \lst@ifdisplaystyle%
                      \small%
                      \fi\ttfamily{},
  breaklines       = true,
  frame            = single,
  framesep         = 0.19em,
  rulecolor        = \color{listing-rule},
  frameround       = ffff,
  tabsize          = 4,
  numberstyle      = \color{listing-numbers},
  aboveskip        = 1.0em,
  belowskip        = 0.1em,
  abovecaptionskip = 0em,
  belowcaptionskip = 1.0em,
  keywordstyle     = {\color{listing-keyword}\bfseries},
  keywordstyle     = {[2]\color{listing-keyword-2}\bfseries},
  keywordstyle     = {[3]\color{listing-keyword-3}\bfseries\itshape},
  sensitive        = true,
  identifierstyle  = \color{listing-identifier},
  commentstyle     = \color{listing-comment},
  stringstyle      = \color{listing-string},
  showstringspaces = false,
  escapeinside     = {/*@}{@*/}, % Allow LaTeX inside these special comments
  literate         =
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\`E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\EUR}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
  {…}{{\ldots}}1 {≥}{{>=}}1 {≤}{{<=}}1 {„}{{\glqq}}1 {“}{{\grqq}}1
  {”}{{''}}1
}
\lstset{style=eisvogel_listing_style}

%
% Java (Java SE 12, 2019-06-22)
%
\lstdefinelanguage{Java}{
  morekeywords={
    % normal keywords (without data types)
    abstract,assert,break,case,catch,class,continue,default,
    do,else,enum,exports,extends,final,finally,for,if,implements,
    import,instanceof,interface,module,native,new,package,private,
    protected,public,requires,return,static,strictfp,super,switch,
    synchronized,this,throw,throws,transient,try,volatile,while,
    % var is an identifier
    var
  },
  morekeywords={[2] % data types
    % primitive data types
    boolean,byte,char,double,float,int,long,short,
    % String
    String,
    % primitive wrapper types
    Boolean,Byte,Character,Double,Float,Integer,Long,Short
    % number types
    Number,AtomicInteger,AtomicLong,BigDecimal,BigInteger,DoubleAccumulator,DoubleAdder,LongAccumulator,LongAdder,Short,
    % other
    Object,Void,void
  },
  morekeywords={[3] % literals
    % reserved words for literal values
    null,true,false,
  },
  sensitive,
  morecomment  = [l]//,
  morecomment  = [s]{/*}{*/},
  morecomment  = [s]{/**}{*/},
  morestring   = [b]",
  morestring   = [b]',
}

\lstdefinelanguage{XML}{
  morestring      = [b]",
  moredelim       = [s][\bfseries\color{listing-keyword}]{<}{\ },
  moredelim       = [s][\bfseries\color{listing-keyword}]{</}{>},
  moredelim       = [l][\bfseries\color{listing-keyword}]{/>},
  moredelim       = [l][\bfseries\color{listing-keyword}]{>},
  morecomment     = [s]{<?}{?>},
  morecomment     = [s]{<!--}{-->},
  commentstyle    = \color{listing-comment},
  stringstyle     = \color{listing-string},
  identifierstyle = \color{listing-identifier}
}

%
% header and footer
%
\usepackage[headsepline,footsepline]{scrlayer-scrpage}

\newpairofpagestyles{eisvogel-header-footer}{
  \clearpairofpagestyles
  \ihead*{NL2SQL in Healthcare}
  \chead*{}
  \ohead*{January 2026}
  \ifoot*{\hspace{0pt}}
  \cfoot*{\thepage}
  \ofoot*{\hspace{0pt}}
  \addtokomafont{pageheadfoot}{\upshape}
}
\pagestyle{eisvogel-header-footer}



%
% Define watermark
%

\begin{document}

\begin{titlepage}
\newgeometry{left=6cm}
\definecolor{titlepage-color}{HTML}{FFFFFF}
\newpagecolor{titlepage-color}\afterpage{\restorepagecolor}
\newcommand{\colorRule}[3][black]{\textcolor[HTML]{#1}{\rule{#2}{#3}}}
\begin{flushleft}
\noindent
\\[-1em]
\color[HTML]{000000}
\makebox[0pt][l]{\colorRule[000000]{1.3\textwidth}{2pt}}
\par
\noindent

{
  \setstretch{1.4}
  \vfill
  \noindent {\huge \textbf{\textsf{Healthcare Analytics Challenges: A
Three-Pillar Framework Connecting Analytics Maturity, Workforce
Dynamics, and Technical Barriers}}}
    \vskip 2em
  \noindent {\Large \textsf{Samuel T Harrold, Yuimedi}}
  \vfill
}


\textsf{January 2026}
\end{flushleft}
\end{titlepage}
\restoregeometry
\pagenumbering{arabic}

% don't generate the default title
% \maketitle
\begin{abstract}
\textbf{Background:} Healthcare organizations face three interconnected
challenges that form a compounding cycle: low analytics maturity (only
39 organizations globally have achieved HIMSS AMAM Stage 6-7), systemic
instability characterized by high leadership turnover (53\% of CIOs with
\textless3 years tenure) and persistent digital skills shortages
reported by 79\% of providers, and technical barriers in natural
language to SQL generation. When these challenges interact, they create
institutional memory loss that threatens data-driven healthcare
transformation.

\textbf{Objective:} This research develops a three-pillar analytical
framework connecting healthcare analytics maturity gaps, workforce
turnover, and technical barriers to data access. The framework reveals
how these challenges interconnect and compound each other.

\textbf{Methods:} We conducted a narrative literature review of
peer-reviewed studies and industry reports on natural language to SQL
generation, healthcare analytics maturity, and workforce turnover. Grey
literature sources were assessed using the AACODS checklist. Evidence
was synthesized through a three-pillar analytical framework examining
how these challenges interconnect and compound each other.

\textbf{Results:} Healthcare-specific text-to-SQL benchmarks (EHRSQL,
SM3-Text-to-Query) show significant progress, though current models are
``not yet sufficiently accurate for unsupervised use'' in clinical
settings. Most healthcare organizations remain at HIMSS AMAM Stages 0-3
with limited predictive capabilities. Healthcare IT turnover
significantly exceeds other IT sectors, creating measurable
institutional memory loss. The three-pillar framework reveals
compounding dynamics: organizations at low maturity stages experience
higher turnover, turnover degrades institutional knowledge needed for
maturity advancement, and technical barriers prevent capturing expertise
before it is lost.

\textbf{Conclusions:} We contribute a three-pillar analytical framework
synthesizing evidence on healthcare analytics maturity, workforce
dynamics, and technical barriers. The framework reveals compounding
effects: low maturity accelerates turnover, turnover degrades maturity,
and technical barriers prevent recovery. This analytical lens enables
organizational self-assessment and informs future research on technology
interventions, including conversational AI platforms as one potential
application.
\end{abstract}


{
\setcounter{tocdepth}{3}
\tableofcontents
}
\setstretch{1.15}
\section{Introduction}\label{introduction}

\subsection{Background}\label{background}

Healthcare analytics has emerged as a critical capability for improving
patient outcomes, reducing costs, and enhancing operational efficiency.
While healthcare organizations must balance cost management, regulatory
compliance, and operational efficiency, these concerns serve a primary
institutional imperative: delivering high-quality patient care.
Analytics initiatives that fail to advance this core mission, or worse,
that divert resources and attention without improving care delivery,
represent a misalignment with healthcare's fundamental purpose.

However, the sector faces unique challenges that distinguish it from
other data-intensive industries. Unlike technology or financial
services, healthcare combines complex clinical workflows, extensive
regulatory requirements, and a workforce with limited technical training
but deep domain expertise
(\citeproc{ref-american2023}{\textbf{american2023?}}).

The Healthcare Information Management Systems Society (HIMSS) Analytics
Maturity Assessment Model (AMAM) provides the industry standard for
measuring healthcare analytics capabilities across seven stages, from
basic data collection to advanced predictive modeling and AI
integration. Recent assessments reveal a sobering reality: as of late
2024, only 26 organizations worldwide had achieved Stage 6 maturity,
with merely 13 reaching Stage 7
(\citeproc{ref-himss2024}{\textbf{himss2024?}},\citeproc{ref-himss2024news}{\textbf{himss2024news?}}).
However, early 2025 has seen an acceleration in high-level validations
driven by the new AMAM24 framework's emphasis on AI governance. Tampa
General Hospital became the first Florida health system to achieve Stage
7 in June 2025, cited specifically for ``responsible AI use''
(\citeproc{ref-tgh2025}{1}), while China Medical University Hospital in
Taiwan advanced to Stage 7 in March 2025 using proprietary AI systems
for anti-microbial stewardship (\citeproc{ref-cmuh2025}{2}). Despite
this progress, the ``Elite Cohort'' remains small.

This analytics maturity crisis occurs amid accelerating technological
advances in natural language processing and conversational AI. Large
language models have demonstrated remarkable capabilities in
understanding clinical terminology, generating SQL queries, and bridging
the gap between natural language questions and structured data analysis.
These developments create unprecedented opportunities to democratize
healthcare analytics access.

Simultaneously, healthcare faces an institutional memory crisis that has
evolved from simple turnover to ``Systemic Instability.'' Recent
evidence reveals a multi-layered workforce crisis affecting leadership,
specialized roles, and new hires. At the strategic level, leadership
churn is acute, with 53\% of healthcare CIOs having a tenure of less
than three years
(\citeproc{ref-wittkieffer2024}{\textbf{wittkieffer2024?}}), creating
frequent shifts in analytics strategy. At the operational level, 79\% of
providers report persistent shortages in ``Information and Digital
Health'' roles
(\citeproc{ref-himssworkforce2024}{\textbf{himssworkforce2024?}}),
leaving critical technical positions vacant. At the foundational level,
approximately 30\% of all new hospital hires leave within their first
year (\citeproc{ref-nsi2025}{\textbf{nsi2025?}}), preventing the
accumulation of tacit knowledge. This churn at every level creates
cascading knowledge loss where expertise cannot stabilize, particularly
in analytics roles where domain knowledge must combine with technical
skills.

\subsection{Problem Statement}\label{problem-statement}

Healthcare organizations face three critical, interconnected challenges
that collectively threaten their ability to become data-driven
enterprises:

\subsubsection{Low Healthcare Analytics
Maturity}\label{low-healthcare-analytics-maturity}

Despite massive investments in electronic health records and data
infrastructure, healthcare organizations struggle to advance beyond
basic reporting capabilities. The HIMSS AMAM reveals that most
organizations remain at Stages 0-3, characterized by fragmented data
sources, limited automated reporting, and minimal predictive
capabilities (\citeproc{ref-himss2024}{\textbf{himss2024?}}). This low
maturity severely constrains evidence-based decision making and
operational optimization.

\subsubsection{Technical Barriers to Data
Access}\label{technical-barriers-to-data-access}

Accessing healthcare insights requires navigating a complex technical
landscape that extends well beyond simple query formulation. While the
immediate barrier is often the ``technical skills gap''---where clinical
experts lack the SQL expertise to query databases directly---this is
merely the surface of a deeper problem. Upstream of query formulation
lie profound challenges in \textbf{Semantic Interoperability}, where
data definitions vary across sites, and \textbf{Data Quality}, where
missing or ``dirty'' data undermines trust
(\citeproc{ref-gal2019}{\textbf{gal2019?}},\citeproc{ref-zhang2024}{\textbf{zhang2024?}}).

In this context, Natural Language to SQL (NL2SQL) generation is not a
``magic bullet'' that solves data chaos. Rather, it serves as a
democratizing \textbf{Interface Layer} and a \textbf{Governance Forcing
Function} (a design feature that compels organizations to formalize and
enforce data governance rules as a precondition for system use). For the
system to function, technical prerequisites must be met: validated
Primary and Foreign Keys and explicit business interpretations (e.g.,
defining ``Length of Stay''). The AI interface forces the organization
to codify these rules, moving them from tacit to explicit knowledge. It
does not replace the hard work of data governance and standardization;
instead, it provides a bridge that allows non-technical domain experts
to interact with data \emph{alongside} these modernization efforts. By
transforming legacy technical requirements into natural language
interactions, AI-assisted interfaces can unlock value from imperfect
data systems while broader interoperability efforts continue
(\citeproc{ref-anthropic2025}{\textbf{anthropic2025?}}). Foundational
research on natural language interfaces to databases established that
modular architecture principles enable effective bridging of legacy data
access challenges (\citeproc{ref-hendrix1978}{\textbf{hendrix1978?}}),
with modern implementations demonstrating that the same large language
models underlying code modernization can serve as natural language
interfaces to legacy systems
(\citeproc{ref-ogunwole2023}{\textbf{ogunwole2023?}}),
(\citeproc{ref-arora2025}{\textbf{arora2025?}}).

\subsubsection{Institutional Memory Loss from Workforce
Turnover}\label{institutional-memory-loss-from-workforce-turnover}

The challenge of retaining healthcare IT talent has evolved from a
structural weakness into a persistent crisis. A foundational 2004 study
established a historical baseline, finding that healthcare IT staff had
the lowest expected tenure for new hires among all IT sectors at just
2.9 years (\citeproc{ref-ang2004}{\textbf{ang2004?}}). While this
structural pattern of high turnover has persisted for two decades,
contemporary evidence indicates the crisis has intensified in the
post-pandemic era.

Recent data paints a stark picture of a workforce under strain. A 2025
analysis of public health informatics specialists reveals that 55\%
intend to leave their positions, signaling a potential exodus of
specialized talent
(\citeproc{ref-rajamani2025}{\textbf{rajamani2025?}}). This aligns with
broader industry signals: the 2023 AHIMA/NORC workforce survey reports
that 83\% of health information professionals face stagnant or
increasing unfilled roles, confirming that vacancy rates are compounding
the loss of experienced staff
(\citeproc{ref-american2023}{\textbf{american2023?}}).

While exact longitudinal tenure data remains scarce, the convergence of
high ``intent to leave'' indicators and persistent ``vacancy rates''
confirms that the institutional memory crisis remains acute. When
experienced analysts leave, they take with them irreplaceable tacit
knowledge---business rules, data anomalies, and analytical
context---that traditional documentation fails to capture.

The implications are measurable in operational terms and patient care
quality. Organizations continue investing in analytics infrastructure
while struggling to realize value from their data assets. Empirical
research demonstrates that a 10-percentage-point increase in nursing
staff turnover is associated with 0.241 additional health inspection
citations and decreased assessment-based quality measures
(\citeproc{ref-shen2023}{\textbf{shen2023?}}). When analytics barriers
are addressed, outcomes improve substantially: one Medicare ACO reduced
readmission rates from 24\% to 17.8\% and achieved \$1.6 million in cost
savings by implementing data analytics to overcome EHR fragmentation
(\citeproc{ref-latrella2024}{\textbf{latrella2024?}}). Technical
barriers remain pervasive, with 68\% of healthcare organizations citing
data interoperability as the leading obstacle to analytics adoption,
followed by privacy concerns (64\%) and insufficient staff training
(59\%) (\citeproc{ref-khan2023}{\textbf{khan2023?}}). Physician
technology adoption faces empirically validated barriers including
perceived threat and inequity from workflow changes, directly impacting
behavioral intentions toward analytics tools
(\citeproc{ref-lin2012}{\textbf{lin2012?}}). These three interconnected
challenges represent operational inefficiencies with demonstrated
implications for healthcare delivery.

\subsection{Objectives}\label{objectives}

This research aims to develop and validate an analytical framework for
understanding healthcare's interconnected analytics challenges. Specific
objectives include:

\subsubsection{Primary Objective}\label{primary-objective}

Develop and validate a three-pillar analytical framework for
understanding how healthcare analytics maturity gaps, workforce
turnover, and technical barriers interconnect and compound each other.

\subsubsection{Secondary Objectives}\label{secondary-objectives}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Synthesize current evidence} on natural language to SQL
  generation as one dimension of technical barriers
\item
  \textbf{Document the extent} of analytics maturity challenges across
  healthcare organizations globally
\item
  \textbf{Quantify the impact} of workforce turnover on institutional
  memory and analytics capabilities
\item
  \textbf{Reveal interconnections} between the three pillars through
  evidence synthesis
\item
  \textbf{Provide assessment rubric} for organizational self-evaluation
  using the framework
\end{enumerate}

\subsubsection{Non-Goals}\label{non-goals}

This research explicitly does not address:

\begin{itemize}
\tightlist
\item
  Specific vendor comparisons or product recommendations
\item
  Implementation details for particular healthcare IT environments
\item
  Regulatory compliance strategies for specific jurisdictions
\item
  Technical architecture specifications for conversational AI systems
\end{itemize}

Note: Analysis of market dynamics and structural factors explaining why
institution-specific analytics challenges persist is within scope. This
market-level analysis provides necessary context for evaluating solution
approaches and differs from product comparison, which would evaluate
specific vendor offerings against each other or recommend particular
products.

\subsection{Contributions}\label{contributions}

This paper makes the following contributions to the healthcare
informatics literature:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Three-Pillar Analytical Framework} (Primary Contribution): We
  synthesize evidence from three previously disconnected research
  domains (healthcare analytics maturity, workforce turnover, and
  natural language processing) into a unified analytical framework that
  reveals how these challenges interconnect and compound each other: low
  maturity accelerates turnover, turnover degrades maturity, and
  technical barriers prevent recovery from either. This framework
  provides an analytical lens for organizational self-assessment and
  research prioritization.
\item
  \textbf{Evidence Synthesis Across Domains}: We document the current
  state of each pillar through comprehensive literature review,
  providing healthcare organizations with consolidated evidence on
  analytics maturity benchmarks, workforce turnover impacts, and NL2SQL
  technical capabilities.
\item
  \textbf{Illustrative Application}: Drawing on established knowledge
  management literature
  (\citeproc{ref-benbya2004}{\textbf{benbya2004?}},\citeproc{ref-richesson2007}{\textbf{richesson2007?}}),
  we describe the validated query cycle as one example of how the
  framework might inform technology design. This architecture concept
  addresses institutional memory loss through six steps: (1) domain
  experts ask natural language questions, (2) the system generates
  candidate SQL, (3) experts validate and correct the SQL, (4) validated
  NL+SQL pairs are stored in organizational memory, (5) future queries
  retrieve validated pairs, and (6) knowledge persists independent of
  staff tenure. Figure 1 illustrates this architecture, and Figure 2
  details the validated query cycle.
\end{enumerate}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth,keepaspectratio]{figures/architecture.mmd.png}
\caption{Healthcare Analytics Architecture. Solid lines indicate the primary data flow from clinical user natural language queries through a conversational AI interface to a healthcare NLP engine for context-aware SQL generation against a healthcare data warehouse, ultimately delivering contextual insights. The critical validation step (dotted line) shows domain experts confirming or correcting generated SQL before results are trusted. Validated NL+SQL pairs flow to organizational memory (dashed line), where they persist independent of staff tenure and inform future query generation.}
\label{fig:architecture}
\end{figure}

\subsubsection{Illustrative Application: The Validated Query
Cycle}\label{illustrative-application-the-validated-query-cycle}

To demonstrate how the three-pillar framework might inform technology
design, we describe a validated query cycle that could address
institutional memory loss (Pillar 2) while reducing technical barriers
(Pillar 3). This six-step cycle (Figure 2) illustrates one approach:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Query}: A domain expert (clinician, analyst, or administrator)
  asks a natural language question about organizational data, such as
  ``What was our 30-day readmission rate for heart failure patients last
  quarter?''
\item
  \textbf{Generation}: The conversational AI system generates candidate
  SQL code from the natural language input, leveraging healthcare
  ontologies and organizational schema knowledge to produce
  syntactically correct queries.
\item
  \textbf{Validation}: The domain expert reviews the generated SQL and
  its results, confirming correctness or providing corrections.
  Following ``Human-on-the-Loop'' (HotL) frameworks proposed in doctoral
  research (\citeproc{ref-bravorocca2023}{\textbf{bravorocca2023?}}),
  this step allows domain experts to guide model adaptation without
  requiring explicit technical task boundaries. It leverages Interactive
  Machine Learning (IML) principles where users supply ``focused,
  frequent, and incremental'' feedback
  (\citeproc{ref-mosqueirarey2023}{\textbf{mosqueirarey2023?}}),
  transforming validation from a binary check into an iterative
  knowledge capture process.
\item
  \textbf{Storage}: Once validated, the NL+SQL pair is stored in
  organizational memory as a durable knowledge artifact. This pair
  represents tested, executable knowledge: a verified mapping from a
  business question to the correct data retrieval logic.
\item
  \textbf{Retrieval}: When future users ask similar questions, the
  system retrieves relevant validated pairs, either returning exact
  matches or using them to inform new query generation. This reduces
  dependence on individual expertise.
\item
  \textbf{Persistence}: When the original expert leaves the
  organization, their analytical knowledge remains embedded in validated
  query pairs. New staff inherit executable knowledge rather than
  starting from scratch or relying on incomplete documentation.
\end{enumerate}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth,keepaspectratio]{figures/knowledge-cycle.mmd.png}
\caption{The Validated Query Cycle, shown as six numbered steps in the diagram. (1) Domain experts ask natural language questions, (2) the system generates candidate SQL, (3) experts validate results, (4) validated pairs are stored, (5) future queries retrieve validated knowledge, and (6) expertise persists through staff turnover. This cycle breaks the compounding effect where turnover erases institutional memory.}
\label{fig:knowledge-cycle}
\end{figure}

This cycle breaks the compounding effect identified in the three-pillar
framework: turnover no longer erases analytical knowledge because
expertise is embedded in validated query pairs rather than individual
memory. Low-maturity organizations can accelerate advancement by
accumulating validated queries, and technical barriers are reduced
because new staff access proven query patterns rather than recreating
analytical logic.

\subsection{Document Structure}\label{document-structure}

Following this introduction, the paper proceeds through five main
sections. The Methodology section describes the narrative review
approach, literature search strategy, and source selection criteria. The
Framework Development section documents how the three-pillar framework
emerged from the literature and its theoretical grounding. The
Literature Review synthesizes evidence across the three pillar domains:
natural language to SQL generation, analytics maturity, and workforce
dynamics. The Discussion examines implications, limitations, and future
research directions. Finally, the Conclusion summarizes the three-pillar
analytical framework as this paper's primary contribution to healthcare
informatics literature.

\section{Methodology}\label{methodology}

\subsection{Review Approach}\label{review-approach}

This paper employs a narrative review methodology to synthesize evidence
across three interconnected domains: healthcare analytics maturity,
workforce turnover, and natural language to SQL technologies. Unlike
systematic reviews that follow pre-registered protocols with exhaustive
searches, narrative reviews provide expert synthesis of relevant
literature to construct coherent arguments and identify patterns across
diverse evidence sources.

The narrative review approach was selected because:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Integration across domains}: The paper synthesizes evidence
  from distinct fields (clinical informatics, human resources, natural
  language processing) that require interpretive integration rather than
  statistical pooling
\item
  \textbf{Original analytical framework}: The three-pillar framework
  emerged iteratively from the literature rather than being
  pre-specified
\item
  \textbf{Heterogeneous evidence types}: The evidence base includes
  peer-reviewed research, industry reports, and benchmark datasets that
  cannot be meaningfully combined through meta-analysis
\end{enumerate}

\subsection{Literature Search}\label{literature-search}

Literature was identified through multiple channels between January 2023
and December 2025:

\textbf{Academic Databases:}

\begin{itemize}
\tightlist
\item
  Crossref: Cross-disciplinary academic literature, citation metadata
\item
  PubMed: Clinical informatics, healthcare workforce, medical
  administration
\item
  arXiv: Machine learning and NLP preprints, benchmark studies
\item
  Semantic Scholar: AI and computer science papers, citation analysis
\end{itemize}

\textbf{Industry Sources:}

\begin{itemize}
\tightlist
\item
  HIMSS: Analytics Maturity Model documentation and industry standards
\item
  Healthcare providers: NHS Trust implementation case studies
\item
  Market research: Precedence Research, Forrester analyst reports
\item
  Technology vendors: Health Catalyst, Oracle, Anthropic technical
  documentation
\item
  Professional associations: AHIMA/NORC workforce surveys
\item
  Business news: IBM, CNBC coverage of healthcare analytics ventures
\end{itemize}

\textbf{Search Concepts:}

Search terms were organized around the three-pillar framework:

\begin{itemize}
\tightlist
\item
  Analytics maturity: ``healthcare analytics maturity,'' ``HIMSS AMAM,''
  ``analytics adoption,'' ``analytics standardization failure,''
  ``low-code healthcare ROI,'' ``conversational AI platforms''
\item
  Workforce turnover: ``healthcare IT tenure,'' ``IT training time,''
  ``turnover cost salary,'' ``institutional memory loss,'' ``knowledge
  portal,'' ``knowledge capture,'' ``SECI model analytics''
\item
  Technical barriers: ``NL2SQL healthcare,'' ``text-to-SQL clinical,''
  ``MIMICSQL,'' ``EHRSQL,'' ``NL2SQL accuracy,'' ``NL2SQL
  productivity,'' ``schema discovery,'' ``PK/FK discovery,'' ``semantic
  column matching,'' ``vector embeddings schema''
\end{itemize}

\textbf{Search Results:}

Searches across all databases yielded 570 initial results after
deduplication. Crossref searches for terms including ``healthcare
analytics maturity,'' ``HIMSS AMAM,'' ``NL2SQL clinical,'' ``knowledge
portal,'' and ``low-code ROI'' (2015-current) returned 285 results, of
which 15 passed screening. PubMed searches combining workforce terms
(``healthcare IT tenure,'' ``IT training time,'' ``turnover cost
salary'') with analytics terms (``institutional memory,'' ``analytics
adoption,'' ``knowledge capture'') (2015-current) yielded 142 results
with 12 passing screening. arXiv searches in cs.CL and cs.DB categories
for ``text-to-SQL'' combined with technical terms (``MIMICSQL,''
``EHRSQL,'' ``schema discovery,'' ``PK/FK discovery,'' ``semantic
matching,'' ``vector embeddings'') (2020-current) produced 71 results
with 6 passing screening. Semantic Scholar searches for ``NL2SQL
healthcare,'' ``NL2SQL productivity,'' ``conversational AI clinical,''
and ``SECI model analytics'' (2015-current) returned 72 results with 8
passing screening. The final corpus includes 81 academic and 11 industry
sources (92 total).

Figure 3 illustrates the literature selection process, showing
progression from initial database search through screening and quality
assessment to the final corpus of 92 sources.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth,keepaspectratio]{figures/literature-flow.mmd.png}
\caption{Literature Selection Flow Diagram. The diagram shows the progression from initial database search (n ≈ 570) through title/abstract screening, full-text review, and quality assessment (AACODS for grey literature) to the final corpus of 92 sources (81 academic, 11 industry). Diagram source available in figures/literature-flow.mmd.}
\label{fig:literature-flow}
\end{figure}

\subsection{Source Selection}\label{source-selection}

Sources were selected based on the following criteria:

\textbf{Inclusion Criteria:}

\begin{itemize}
\tightlist
\item
  Peer-reviewed publications in healthcare informatics, medical
  informatics, computer science, or health services research
\item
  Industry reports from established healthcare IT organizations (HIMSS,
  AHIMA, AMIA)
\item
  Publications from 2015-current, with emphasis on 2020-current for
  rapidly evolving NL2SQL technologies
\item
  English language publications
\item
  Sources with verifiable DOIs, URLs, or institutional attribution
\end{itemize}

\textbf{Exclusion Criteria:}

\begin{itemize}
\tightlist
\item
  Sources without verifiable attribution or institutional backing
\item
  Vendor marketing materials without independent validation
\item
  Preprints without subsequent peer-reviewed publication (exception:
  foundational NL2SQL benchmarks where peer review is pending)
\item
  Studies with unverifiable statistics or methodological concerns
\end{itemize}

\subsection{Evidence Synthesis}\label{evidence-synthesis}

Evidence was synthesized thematically around the three-pillar framework:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Analytics maturity}: Evidence on HIMSS AMAM adoption,
  healthcare analytics capabilities, and organizational readiness
\item
  \textbf{Workforce turnover}: Evidence on nursing and IT staff turnover
  rates, institutional memory loss, and knowledge transfer challenges
\item
  \textbf{Technical barriers}: Evidence on NL2SQL benchmarks,
  healthcare-specific NLP challenges, and low-code implementation
  patterns
\end{enumerate}

This framework emerged iteratively from the literature rather than being
pre-specified, consistent with narrative review methodology.

\subsection{Grey Literature Quality
Assessment}\label{grey-literature-quality-assessment}

Grey literature sources were assessed using the AACODS checklist
(\citeproc{ref-tyndall2010}{\textbf{tyndall2010?}}), which evaluates
Authority, Accuracy, Coverage, Objectivity, Date, and Significance.
Sources with vendor sponsorship were retained when no independent
alternative existed but flagged in-text. Table \ref{tab:aacods}
summarizes the assessment.

\begin{sidewaystable}
\centering
\caption{AACODS Assessment of Industry Sources}
\small
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
\textbf{Source} & \textbf{Authority} & \textbf{Accuracy} & \textbf{Coverage} & \textbf{Objectivity} & \textbf{Date} & \textbf{Significance} & \textbf{Include} \\
\hline
{[}I1{]} HIMSS AMAM & High$^\dagger$ & Verifiable & Global & High & 2024 & High & Yes \\
{[}I2{]} Snowdon/HIMSS & High$^\ddagger$ & Verifiable & N/A & High & 2024 & Medium & Yes \\
{[}I3{]} Health Catalyst & Medium$^\S$ & Unverifiable & US & Low & 2020 & Medium & Yes* \\
{[}I4{]} Berkshire NHS & High$^\P$ & Verifiable & Single site & High & 2024 & High & Yes \\
{[}I5{]} Forrester/Microsoft & Medium$^\|$ & Unverifiable & Enterprise & Low$^\diamondsuit$ & 2024 & Medium & Yes* \\
{[}I6{]} Oracle & Low$^\S$ & Unverifiable & N/A & Low & 2024 & Low & Yes* \\
{[}I7{]} Precedence Research & Medium$^\#$ & Unverifiable & Global & Medium & 2024 & Medium & Yes \\
{[}I8{]} Anthropic & Medium$^\S$ & Verifiable & N/A & Medium & 2025 & Low & Yes \\
{[}I9{]} IBM Newsroom & High$^{**}$ & Verifiable & N/A & High & 2022 & High & Yes \\
{[}I10{]} CNBC/Haven & High$^{**}$ & Verifiable & N/A & High & 2021 & High & Yes \\
{[}I11{]} AHIMA/NORC & High$^{\dagger\dagger}$ & Verifiable & US & High & 2023 & High & Yes \\
\hline
\end{tabular}
\label{tab:aacods}

\footnotesize
$^\dagger$Industry standards body.
$^\ddagger$HIMSS officer.
$^\S$Vendor.
$^\P$NHS trust.
$^\|$Analyst firm.
$^\#$Market research.
$^{**}$Journalism.
\\
$^{\dagger\dagger}$Professional association + academic.
$^\diamondsuit$Sponsor.
*Vendor sponsorship or low objectivity noted in manuscript text.
\end{sidewaystable}

\subsection{Methodological
Limitations}\label{methodological-limitations}

This narrative review has inherent limitations:

\begin{itemize}
\tightlist
\item
  \textbf{Non-exhaustive search}: Literature identification was
  selective rather than exhaustive; relevant studies may have been
  missed
\item
  \textbf{Limited formal quality assessment}: Grey literature sources
  were assessed using the AACODS checklist; however, no standardized
  quality assessment tool (e.g., GRADE, Cochrane Risk of Bias) was
  applied to peer-reviewed sources, as these tools are designed for
  clinical intervention studies rather than narrative reviews
\item
  \textbf{Single-coder bias risk}: Literature screening, data
  extraction, and thematic analysis were performed by a single author
  without independent verification. This introduces potential selection
  and interpretation bias that would be mitigated in systematic reviews
  through dual-coder protocols with inter-rater reliability assessment
\item
  \textbf{Post-hoc selection criteria}: Inclusion and exclusion criteria
  were refined during the review process rather than pre-registered
\item
  \textbf{No protocol registration}: This review was not registered in
  PROSPERO or similar registries
\item
  \textbf{Critical data gap in workforce statistics}: The lack of
  longitudinal tenure data specific to Healthcare Analytics \&
  Informatics Professionals is a critical \emph{blind spot} in the
  literature. While clinical turnover is well-tracked, the primary
  statistic for IT turnover (\textasciitilde34\% implied for new hires)
  relies on Ang and Slaughter's 2004 study
  (\citeproc{ref-ang2004}{\textbf{ang2004?}}). This statistical void
  obscures the true severity of institutional memory decay, representing
  a primary finding of this review: the industry lacks the modern
  metrics necessary to quantify its own systemic instability.
\end{itemize}

These limitations are balanced against the strengths of narrative review
methodology: ability to synthesize heterogeneous evidence types across
disciplinary boundaries, flexibility to pursue emerging themes, and
capacity to construct novel analytical frameworks that illuminate
connections between previously disconnected research domains.

\section{Framework Development and
Validation}\label{framework-development-and-validation}

This paper's primary contribution is the three-pillar analytical
framework for understanding healthcare analytics challenges: (1)
analytics maturity gaps, (2) workforce turnover and institutional memory
loss, and (3) technical barriers in natural language to SQL generation.
This section documents the framework's development process and
theoretical grounding.

\subsection{Framework Development
Process}\label{framework-development-process}

The three-pillar framework emerged through iterative analysis of the
literature corpus. Initial review identified numerous disconnected
research streams: NL2SQL technical advances, HIMSS maturity models,
healthcare workforce turnover studies, knowledge management theory, and
healthcare IT implementation case studies. These appeared as isolated
topics until thematic analysis revealed recurring patterns of
interdependence.

The framework development followed these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Theme Extraction}: Systematic coding of 92 sources identified
  recurring themes across technical, organizational, and workforce
  dimensions
\item
  \textbf{Pattern Recognition}: Cross-domain analysis revealed that
  challenges in each dimension amplified challenges in others (e.g.,
  workforce turnover degrading analytics maturity, technical barriers
  preventing knowledge capture)
\item
  \textbf{Pillar Identification}: Three orthogonal yet interconnected
  dimensions emerged as the organizing structure:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Analytics Maturity}: Organizational capability progression
    measured against HIMSS AMAM stages
  \item
    \textbf{Workforce Dynamics}: Human capital retention and tacit
    knowledge preservation
  \item
    \textbf{Technical Barriers}: NL2SQL capabilities and
    healthcare-specific implementation challenges
  \end{itemize}
\item
  \textbf{Framework Validation}: Pillar structure tested against all 92
  sources to confirm comprehensive coverage without significant gaps
\end{enumerate}

\subsection{Theoretical Grounding}\label{theoretical-grounding}

The three-pillar framework aligns with established models in healthcare
informatics and knowledge management:

\begin{table}[htbp]
\centering
\caption{Framework Alignment with Established Models}
\label{tab:framework-alignment}
\begin{tabular}{p{3cm}p{3.5cm}p{3.5cm}p{3.5cm}}
\toprule
\textbf{Three \newline Pillars} & \textbf{HIMSS AMAM Alignment} & \textbf{DIKW \newline Hierarchy} & \textbf{Knowledge Management} \\
\midrule
Analytics \newline Maturity & Stages 0-7 \newline Progression & Data \newline → Information & Organizational learning \\
Workforce \newline Dynamics & Implicit in \newline Advanced Stages & Knowledge (tacit) \newline → Wisdom & Tacit knowledge transfer \\
Technical \newline Barriers & Stage 6-7 \newline Requirements & Information \newline → Knowledge & Knowledge \newline Codification \\
\bottomrule
\end{tabular}
\end{table}

The HIMSS Analytics Maturity Assessment Model
(\citeproc{ref-himss2024}{\textbf{himss2024?}}) provides organizational
benchmarks but does not explicitly address workforce knowledge
retention. The Data-Information-Knowledge-Wisdom (DIKW) hierarchy
explains the progression from raw data to actionable insight, but
standard formulations do not address institutional memory loss. The
three-pillar framework synthesizes these perspectives, positioning
workforce dynamics as the critical enabler connecting data access
(analytics maturity) with organizational wisdom (knowledge
preservation).

\subsection{Framework Scope and
Limitations}\label{framework-scope-and-limitations}

The framework is descriptive rather than prescriptive; it provides an
analytical lens for understanding healthcare analytics challenges but
does not mandate specific solutions. Future research should empirically
validate pillar interdependencies through longitudinal organizational
studies and develop quantitative metrics for framework dimensions.

\section{Literature Review: Evidence Across the Three
Pillars}\label{literature-review-evidence-across-the-three-pillars}

This narrative review synthesizes evidence across the three-pillar
framework domains: natural language to SQL generation (technical
barriers), healthcare analytics maturity, and workforce dynamics.
Drawing from peer-reviewed research, industry reports, and benchmark
datasets identified through the methodology described in Section 2
(Methodology), we document the current state of each pillar and reveal
interconnections. Analysis reveals three critical findings: (1) natural
language to SQL generation has evolved significantly but faces
healthcare-specific challenges requiring specialized solutions, (2)
healthcare analytics maturity remains low with most organizations
struggling at basic stages, and (3) healthcare workforce turnover
creates institutional memory loss that traditional approaches fail to
address. Evidence across these three domains reveals significant
interconnections and compounding effects that the three-pillar framework
synthesizes.

\subsection{Current State of Natural Language to SQL
Generation}\label{current-state-of-natural-language-to-sql-generation}

\subsubsection{Evolution and Technical
Advances}\label{evolution-and-technical-advances}

Recent systematic reviews document the rapid evolution of natural
language to SQL (NL2SQL) technologies. Ziletti and D'Ambrosi
(\citeproc{ref-ziletti2024}{\textbf{ziletti2024?}}) demonstrate that
retrieval augmented generation (RAG) approaches significantly improve
query accuracy when applied to electronic health records (EHRs), though
they note that ``current language models are not yet sufficiently
accurate for unsupervised use'' in clinical settings; this assessment,
based on 2024 models, has been challenged by late-2025 benchmarks
showing GPT-5 exceeds physician baselines on standardized medical
reasoning tasks (\citeproc{ref-wang2025}{\textbf{wang2025?}}),
(\citeproc{ref-openai2025}{\textbf{openai2025?}}), though human
oversight remains recommended for clinical safety. Their work on the
DE-SynPUF dataset shows that integrating medical coding steps into the
text-to-SQL process improves performance over simple prompting
approaches.

Benchmarking studies from 2024-2025
(\citeproc{ref-medagentbench2024}{\textbf{medagentbench2024?}}),
(\citeproc{ref-wu2024a}{\textbf{wu2024a?}}) examining LLM-based systems
for healthcare identify unique challenges: medical terminology,
characterized by abbreviations, synonyms, and context-dependent
meanings, remains a barrier to accurate query generation. Evaluations of
GPT-4 and Claude 3.5 showed approximately 64-70\% accuracy on complex
clinical and agent-based tasks; however, late-2025 models demonstrate
substantial improvements. GPT-5 achieves over 80\% accuracy on
neurosurgical board examinations and surpasses physician performance on
multimodal medical reasoning benchmarks by 15-29\%
(\citeproc{ref-wang2025}{\textbf{wang2025?}}). On healthcare-specific
NL2SQL tasks, GPT-5 achieves 64.6\% execution accuracy on the MIMICSQL
dataset (\citeproc{ref-blaskovic2025}{\textbf{blaskovic2025?}}), while
the HealthBench benchmark (developed with 262 physicians across 26
specialties) shows GPT-5 hallucination rates of 0.7-1.0\%, representing
a 4-6x improvement over previous models
(\citeproc{ref-openai2025}{\textbf{openai2025?}}).

\subsubsection{Healthcare-Specific
Challenges}\label{healthcare-specific-challenges}

The literature consistently identifies domain-specific obstacles in
healthcare NL2SQL implementation. A systematic review of NLP in EHRs
(\citeproc{ref-navarro2023}{\textbf{navarro2023?}}) found that the lack
of annotated data, automated tools, and other challenges hinder the full
utilization of NLP for EHRs. The review, following PRISMA guidelines,
categorized healthcare NLP applications into seven areas, with
information extraction and clinical entity recognition proving most
challenging due to medical terminology complexity.

Wang et al. (\citeproc{ref-wang2020}{\textbf{wang2020?}}) demonstrate
that healthcare NL2SQL methods must move beyond the constraints of exact
or string-based matching to fully encompass the semantic complexities of
clinical terminology. This work emphasizes that general-purpose language
models fail to capture the nuanced relationships between medical
concepts, diagnoses codes (ICD), procedure codes (CPT), and medication
vocabularies (RxNorm).

\subsubsection{Promising Approaches and
Limitations}\label{promising-approaches-and-limitations}

Recent advances show promise in addressing these challenges. The
TREQS/MIMICSQL dataset development
(\citeproc{ref-wang2020}{\textbf{wang2020?}}) and EHRSQL benchmark
(\citeproc{ref-lee2023}{\textbf{lee2023?}}) provide question-SQL pairs
specifically for healthcare, featuring questions in natural, free-form
language. Multi-modal benchmarks such as SM3-Text-to-Query
(\citeproc{ref-sivasubramaniam2024}{\textbf{sivasubramaniam2024?}})
extend evaluation beyond SQL to support multiple query languages across
diverse medical data representations. This approach acknowledges that
healthcare queries often require multiple logical steps: population
selection, temporal relationships, aggregation statistics, and
mathematical operations.

Healthcare-specific benchmarks continue to evolve alongside model
capabilities. The 2024 MedAgentBench evaluation found Claude 3.5 Sonnet
achieved 69.67\% success rate on medical agent tasks
(\citeproc{ref-medagentbench2024}{\textbf{medagentbench2024?}}),
(\citeproc{ref-wu2024a}{\textbf{wu2024a?}}); subsequent 2025 benchmarks
show GPT-5 significantly exceeding these results, with the SCARE
benchmark (\citeproc{ref-lee2025}{\textbf{lee2025?}}) providing 4,200
EHR question-SQL pairs across MIMIC-III, MIMIC-IV, and eICU databases
specifically designed to evaluate post-hoc safety mechanisms for
clinical text-to-SQL deployment. Graph-empowered approaches combining
LLMs with structured knowledge representations achieve 94.2\% execution
accuracy on MIMICSQL (\citeproc{ref-chen2025}{\textbf{chen2025?}}),
demonstrating that domain-specific architectural innovations can
substantially outperform general-purpose models. While these advances
narrow the gap between benchmark performance and clinical readiness,
domain-specific challenges in medical terminology and complex clinical
reasoning remain active research areas.

\subsubsection{Productivity and Efficiency
Evidence}\label{productivity-and-efficiency-evidence}

Emerging research documents quantifiable productivity gains from NL2SQL
implementations. In healthcare settings, organizations implementing
natural language interfaces report a 63\% increase in self-service
analytics adoption among non-technical staff and a 37\% reduction in
time spent on data retrieval tasks
(\citeproc{ref-dadi2025}{\textbf{dadi2025?}}). Business analysts using
these interfaces spend 42\% more time on analysis rather than query
construction (\citeproc{ref-dadi2025}{\textbf{dadi2025?}}).

Clinical-specific natural language interfaces demonstrate significant
efficiency improvements. Criteria2Query, a natural language interface
for clinical database cohort definition, achieves fully automated query
formulation in an average of 1.22 seconds per criterion, enabling
researchers to query EHR data without mastering database query languages
(\citeproc{ref-yuan2019}{\textbf{yuan2019?}}). The system has evolved
through three generations: the original rule-based approach
(\citeproc{ref-yuan2019}{\textbf{yuan2019?}}), a human-machine
collaboration version, and Criteria2Query 3.0, which leverages GPT-4 to
generate sharable cohort identification queries against OMOP-CDM
formatted databases (\citeproc{ref-park2024}{\textbf{park2024?}}). User
studies show NL2SQL systems reduce query completion times by 10-30\%
compared to traditional SQL platforms while improving accuracy from 50\%
to 75\%, with users recovering from errors 30-40 seconds faster
(\citeproc{ref-ipeirotis2025}{\textbf{ipeirotis2025?}}).

The most substantial productivity gains appear in multimodal interfaces.
Research on speech-driven database querying demonstrates users can
specify SQL queries with an average speedup of 2.7x (up to 6.7x)
compared to traditional input methods, with user effort reduced by a
factor of 10x to 60x compared to raw typing
(\citeproc{ref-shah2020}{\textbf{shah2020?}}). Healthcare-specific
natural language query systems show dramatic improvements: a clinical
data analytics language (CliniDAL) reduced complex query formulation
from ``many days'' with SQL to ``a few hours'' with natural language,
with expert users describing SQL as ``very tedious and time-consuming''
for the same analytical tasks
(\citeproc{ref-safari2014}{\textbf{safari2014?}}). NLP-driven data entry
systems have achieved 33\% time reduction with 15\% accuracy improvement
in clinical research settings
(\citeproc{ref-han2019}{\textbf{han2019?}}). Healthcare-specific NL2SQL
models such as MedT5SQL achieve 80.63\% exact match accuracy on the
MIMICSQL benchmark, demonstrating that domain-adapted language models
can effectively translate natural language to SQL for clinical databases
(\citeproc{ref-marshan2024}{\textbf{marshan2024?}}). These metrics
provide peer-reviewed evidence that complements vendor-sponsored
efficiency claims.

Code modernization principles directly inform these productivity gains.
Foundational work on natural language interfaces to databases
(\citeproc{ref-hendrix1978}{\textbf{hendrix1978?}}) established that
modular, decoupled architecture enables effective NL access to legacy
systems, a design principle applied across subsequent research (e.g.,
(\citeproc{ref-saha2023}{\textbf{saha2023?}})). Modern implementations
demonstrate that retrieval-augmented generation (RAG) approaches reduce
specialized training requirements by 87.4\% compared to traditional
querying methods while achieving 92.3\% accuracy in interpreting
business-specific terminology from legacy mainframe records
(\citeproc{ref-khandelwal2025}{\textbf{khandelwal2025?}}). This
convergence of code modernization and natural language interface
technologies arises because both rely on the same underlying large
language models (\citeproc{ref-ogunwole2023}{\textbf{ogunwole2023?}}),
(\citeproc{ref-arora2025}{\textbf{arora2025?}}), suggesting that
organizations investing in either capability simultaneously advance
both.

\subsection{State of Healthcare Analytics
Maturity}\label{state-of-healthcare-analytics-maturity}

\subsubsection{Low Organizational
Maturity}\label{low-organizational-maturity}

The Healthcare Information Management Systems Society (HIMSS) Analytics
Maturity Assessment Model (AMAM) provides the industry standard for
measuring analytics capabilities. Recent data reveals a concerning state
of analytics maturity in healthcare organizations globally
(\citeproc{ref-himss2024}{\textbf{himss2024?}}). The newly revised
AMAM24 model, launched in October 2024, represents a significant
evolution from the original framework.

Snowdon (\citeproc{ref-snowdon2024b}{\textbf{snowdon2024b?}}), Chief
Scientific Research Officer at HIMSS, emphasizes that ``analytics as a
discipline has changed dramatically in the last five to 10 years,'' yet
healthcare organizations struggle to keep pace
(\citeproc{ref-wang2018}{\textbf{wang2018?}}). Research confirms
healthcare's adoption of analytics often lags behind other sectors such
as retail and banking, partly due to the complexity of implementing new
technology in clinical environments
(\citeproc{ref-wang2018}{\textbf{wang2018?}}),
(\citeproc{ref-wang2017}{\textbf{wang2017?}}). The newly revised AMAM
model shifts focus from technical capabilities to outcomes and AI
governance, requiring evidence of responsible algorithm monitoring
(\citeproc{ref-himss2024apac}{3}). This shift drove the 2025 validations
of Tampa General and CMUH, confirming that AI readiness is the new
gatekeeper for analytics maturity. Regional adoption dynamics reveal
distinct structural drivers: while North American adoption is largely
market-driven by value-based care, Middle Eastern adoption is often
characterized by government-mandated visions, such as Saudi Arabia's
centralized push for digital health excellence which has propelled
institutions like King Faisal Specialist Hospital to Stage 7
(\citeproc{ref-ksa2024}{4}).

Quantitative evidence links organizational maturity to patient outcomes
through two related pathways. First, EMR adoption maturity provides
foundational infrastructure: cross-sectional studies using the HIMSS
Electronic Medical Record Adoption Model (EMRAM) demonstrate that
hospitals with advanced EMR adoption (levels 6-7) have 3.25 times higher
odds of achieving better Leapfrog Group Hospital Safety Grades compared
to hospitals at EMRAM level 0, with significantly reduced infection
rates and fewer adverse events
(\citeproc{ref-snowdon2024}{\textbf{snowdon2024?}}). Similarly,
high-maturity hospitals have 1.8 to 2.24 times higher odds of achieving
higher patient experience ratings
(\citeproc{ref-snowdon2024a}{\textbf{snowdon2024a?}}). Second, analytics
capabilities build on this digital foundation: big data analytics
capabilities, combined with complementary organizational resources and
analytical personnel skills, improve readmission rates and patient
satisfaction (\citeproc{ref-wang2019}{\textbf{wang2019?}}), while
poor-quality data results in diagnostic errors, ineffective treatments,
and compromised patient care
(\citeproc{ref-gomes2025}{\textbf{gomes2025?}}). Note that EMRAM
measures EMR adoption stages rather than analytics maturity directly;
robust digital infrastructure is a prerequisite for analytics, but the
AMAM model addresses the analytics-specific capability gap. However,
evidence explicitly linking the new AMAM framework to outcomes remains
sparse. Studies relying on older proxies yield mixed results: while some
align digital maturity with lower staff turnover and reduced errors
(\citeproc{ref-woods2024}{\textbf{woods2024?}}), others find no
significant association with readmission rates
(\citeproc{ref-saintulysse2021}{\textbf{saintulysse2021?}}) or mortality
(\citeproc{ref-martin2019}{\textbf{martin2019?}}), suggesting that
maturity alone is insufficient without workforce stability.

\subsubsection{Barriers to Analytics
Adoption}\label{barriers-to-analytics-adoption}

A systematic literature review of big data analytics in healthcare by
Kamble et al. (\citeproc{ref-kamble2019}{\textbf{kamble2019?}})
identifies critical barriers to analytics adoption. The study reveals
that healthcare enterprises struggle with technology selection, resource
allocation, and organizational readiness for data-driven decision
making.

Health Catalyst's Healthcare Analytics Adoption Model
(\citeproc{ref-health2020}{\textbf{health2020?}}), a vendor-produced
framework, corroborates these findings, documenting that most healthcare
organizations remain at Stages 0-3, characterized by:

\begin{itemize}
\tightlist
\item
  Fragmented data sources without integration
\item
  Limited automated reporting capabilities
\item
  Lack of standardized data governance
\item
  Minimal predictive or prescriptive analytics
\item
  Absence of real-time decision support
\end{itemize}

\subsubsection{The Analytics Skills Gap}\label{the-analytics-skills-gap}

The literature consistently identifies workforce capabilities as a
primary constraint. Healthcare organizations face mounting challenges in
extracting meaningful insights from the vast amount of unstructured
clinical text data generated daily
(\citeproc{ref-navarro2023}{\textbf{navarro2023?}}). There is an
acknowledged problem in health services where organizations cannot make
good use of available data due to a deficit in skilled analysts across
all sectors and levels
(\citeproc{ref-bardsley2016}{\textbf{bardsley2016?}}). Organizations
face critical challenges in recruiting and retaining professionals with
the right analytical skills, while the need for big data specialists
with analytical capabilities continues to grow
(\citeproc{ref-pesqueira2020}{\textbf{pesqueira2020?}}). Traditional
approaches to analytics require extensive technical expertise and time
that healthcare professionals typically lack, creating a fundamental
barrier to analytics adoption
(\citeproc{ref-american2023}{\textbf{american2023?}}).

\subsubsection{Data Quality as a Barrier to Analytics
Maturity}\label{data-quality-as-a-barrier-to-analytics-maturity}

Beyond workforce constraints, data quality represents a fundamental
barrier preventing healthcare organizations from advancing their
analytics capabilities. Research consistently demonstrates that data
quality is both a prerequisite for and a dimension of analytics
maturity; organizations cannot progress to higher maturity stages
without first addressing data quality issues
(\citeproc{ref-carvalho2019}{\textbf{carvalho2019?}}). Multiple maturity
frameworks, including the Healthcare Data Quality Maturity Model (HDQM2)
and the Data Analytics Maturity Assessment Framework (DAMAF), explicitly
incorporate data quality as a core assessment dimension
(\citeproc{ref-pintovalverde2013}{\textbf{pintovalverde2013?}},\citeproc{ref-gokalp2023}{\textbf{gokalp2023?}}).
A cross-industry survey found that data management and quality issues,
including lack of documentation, accuracy, and consistency, continue to
challenge analytics organizations even as they mature, with the specific
challenges shifting from integration to privacy and documentation
concerns at higher maturity levels
(\citeproc{ref-lismont2017}{\textbf{lismont2017?}}).

The prevalence of data quality issues in healthcare databases is
substantial. A study of the National Cancer Database found missing data
rates ranging from 39.7\% for prostate cancer to 71.0\% for non-small
cell lung cancer (\citeproc{ref-yang2021}{\textbf{yang2021?}}). Medical
registry data shows 2.0\% to 4.6\% inaccurate records and 5\% to 6\%
incomplete data (\citeproc{ref-arts2002}{\textbf{arts2002?}}). Duplicate
patient records affect 0.16\% to 15.47\% of records across healthcare
institutions, with wide variation in management practices
(\citeproc{ref-mccoy2013}{\textbf{mccoy2013?}}). Analysis of Medicaid
claims data found that 9.74\% of data cells contained defects, with
issues frequently remaining obscure due to separation between data users
and producers (\citeproc{ref-zhang2024}{\textbf{zhang2024?}}).

Critically, automated data quality tools alone are insufficient for
healthcare data. Research demonstrates that clinical domain expert
involvement is necessary at every stage of the data pipeline, including
curation, cleaning, and analysis
(\citeproc{ref-rahman2020}{\textbf{rahman2020?}}). Automated tools fail
to detect context-dependent errors such as mutually exclusive values,
definitional differences between institutions, or plausibility issues
that require clinical judgment
(\citeproc{ref-sirgo2018}{\textbf{sirgo2018?}}). Even successful
automation requires embedding clinical knowledge; generic automated
cleaning tools from other domains are unsuitable for clinical data,
which requires variable-specific rules based on clinical knowledge of
normal ranges, extreme values, and clinical contexts
(\citeproc{ref-shi2021}{\textbf{shi2021?}}).

Compounding these challenges, healthcare database schemas are frequently
undocumented or poorly documented. Commercial EMR systems use
proprietary data models that are not publicly available, requiring
``detective work'' and reverse-engineering for research data integration
(\citeproc{ref-dugas2016}{\textbf{dugas2016?}},\citeproc{ref-bokov2017}{\textbf{bokov2017?}}).
A systematic review found that metadata models are often too complicated
for healthcare professionals without specific IT skills, resulting in
rare usage and poorly maintained documentation
(\citeproc{ref-ulrich2022}{\textbf{ulrich2022?}}). Poor chart
documentation by healthcare providers propagates downstream to
administrative data quality issues
(\citeproc{ref-lucyk2017}{\textbf{lucyk2017?}}). Most critically,
documentation knowledge is lost with staff changes: decisions based on
poorly documented data represent significant costs and risks, with
explicit identification of ``loss of information with staff changes'' as
a key vulnerability (\citeproc{ref-hovenga2013}{\textbf{hovenga2013?}}).

This creates a compounding effect across the three pillars: low-maturity
organizations have worse data quality and documentation, which requires
domain expertise to address, but that expertise is lost through
workforce turnover, further degrading data quality and preventing
maturity advancement.

\subsection{Healthcare Workforce Turnover and Knowledge
Loss}\label{healthcare-workforce-turnover-and-knowledge-loss}

\subsubsection{Turnover Rates and Financial
Impact}\label{turnover-rates-and-financial-impact}

Multiple meta-analyses provide comprehensive data on healthcare
workforce turnover. Wu et al. (\citeproc{ref-wu2024}{\textbf{wu2024?}})
found a pooled prevalence of nurse turnover at 18\% (95\% CI: 11-26\%),
with individual study rates ranging from 2.2\% to 50.0\% across 15
countries, including a reported range of 11.7\% to 46.7\% within the
United States. Ren et al. (\citeproc{ref-ren2024}{\textbf{ren2024?}})
corroborated these findings with a global nurse turnover rate ranging
from 8\% to 36.6\%, with a pooled rate of 16\% (95\% CI: 14-17\%).

The financial implications are substantial. Massingham
(\citeproc{ref-massingham2018}{\textbf{massingham2018?}}) measured the
impact of knowledge loss in a longitudinal study, finding that the total
financial cost to address problems caused by knowledge loss reached
three times the organization's annual salary budget, including increased
training costs, productivity losses, and project delays.
Healthcare-specific evidence quantifies replacement costs in absolute
terms: nurse turnover costs 1.2-1.3 times the registered nurse's annual
salary, with the highest cost categories being vacancy,
orientation/training, and new employee productivity loss
(\citeproc{ref-jones2005}{\textbf{jones2005?}}); replacing a primary
care clinician costs healthcare organizations over \$500,000 due to lost
revenue and recruiting expenses
(\citeproc{ref-willardgrace2019}{\textbf{willardgrace2019?}}); while
physician replacement can reach up to \$1 million per departure, with
national annual costs estimated at \$4.6 billion
(\citeproc{ref-melnick2021}{\textbf{melnick2021?}}). Vendor analysis
from Oracle (\citeproc{ref-oracle2024}{\textbf{oracle2024?}})
corroborates these findings, documenting turnover costs at 0.5-2.0 times
annual salary with knowledge-intensive positions reaching the higher
end.

Technical and analytics staff face acute instability that extends beyond
general turnover baselines. While hospital-wide data establishes a high
churn environment, with 30\% of all new hires leaving within their first
year (\citeproc{ref-nsi2025}{\textbf{nsi2025?}}), the crisis in
technology roles is distinct and severe. Recent industry assessments
reveal shortages at both leadership and operational levels.
Strategically, 53\% of healthcare CIOs have held their current role for
less than three years
(\citeproc{ref-wittkieffer2024}{\textbf{wittkieffer2024?}}), creating
leadership vacuums that disrupt long-term analytics initiatives.
Operationally, this instability is compounded by persistent vacancies,
with 79\% of providers reporting shortages in ``Information and Digital
Health'' roles
(\citeproc{ref-himssworkforce2024}{\textbf{himssworkforce2024?}}). This
creates a ``revolving door'' for innovation-focused staff, significantly
impacting the continuity required for complex modernization.
Contemporary evidence supports this trend: a 2025 analysis of nationally
representative US survey data (n=44,732) found that 55\% of public
health informatics specialists intended to leave their positions
(\citeproc{ref-rajamani2025}{\textbf{rajamani2025?}}). The 2023
AHIMA/NORC workforce survey found that 66\% of health information
professionals report persistent staffing shortages, with 83\% reporting
that unfilled roles increased or remained stagnant over the past year
(\citeproc{ref-american2023}{\textbf{american2023?}}).

The knowledge loss implications are substantial. Research documents
significant time-to-productivity requirements across healthcare IT
roles: basic EHR training requires 8 hours to 2 months for end-users,
while health information workforce development demands 18 months to 2
years for specialized roles
(\citeproc{ref-ledikwe2013}{\textbf{ledikwe2013?}}). International
Medical Informatics Association recommendations specify a minimum of 1
year (60 ECTS credits) for biomedical and health informatics specialists
(\citeproc{ref-mantas2010}{\textbf{mantas2010?}}), with personalized EHR
training programs requiring 6 months of blended instruction to achieve
meaningful competency improvements
(\citeproc{ref-musa2023}{\textbf{musa2023?}}). For IT developers and
specialists, research suggests up to 3 years are required to become
fully fluent in complex healthcare IT projects
(\citeproc{ref-konrad2022}{\textbf{konrad2022?}}). Given these
relatively short tenures, many healthcare IT professionals spend only a
limited portion of their employment at full productivity and, in the
case of IT developers, are likely to leave before reaching full fluency.
This creates a perpetual cycle where organizations lose experienced
staff before fully recouping their training investment.

The impact on care continuity is well-documented. Clinical handover
disruption is internationally recognized as a patient safety priority
because it represents a fundamental disruption to continuity of care and
is prone to errors
(\citeproc{ref-rangachari2020}{\textbf{rangachari2020?}}). Empirical
studies demonstrate that nursing unit turnover reduces workgroup
learning and is associated with increased patient falls, medication
errors, and reduced patient satisfaction
(\citeproc{ref-bae2010}{\textbf{bae2010?}}). International evidence
links high workforce turnover to poorer continuity of care, particularly
in remote health services, with measurable outcomes including increased
hospitalizations and years of life lost
(\citeproc{ref-wakerman2019}{\textbf{wakerman2019?}}). When senior
executives and knowledge workers depart, organizations experience
``corporate memory loss'' that undermines organizational continuity and
effectiveness (\citeproc{ref-lahaie2005}{\textbf{lahaie2005?}}).

\subsubsection{Institutional Memory
Loss}\label{institutional-memory-loss}

The concept of institutional memory in healthcare has received
increasing attention. Institutional memory encompasses the collective
knowledge, experiences, and expertise that enables organizational
effectiveness. Healthcare organizations typically lack formal mechanisms
for knowledge preservation, relying instead on person-to-person transfer
that fails during rapid turnover. Cultural and regulatory obstacles for
data sharing further limit the ability of healthcare organizations to
achieve the full potential of their data assets
(\citeproc{ref-mayo2016}{\textbf{mayo2016?}}).

When experienced analysts, clinical informatics professionals, or
data-savvy clinicians leave, they take with them irreplaceable knowledge
about data definitions, business rules, analytical approaches, and
organizational context. Research on tacit knowledge transfer provides
strong evidence that this knowledge is inherently difficult to document
through traditional means. Empirical studies demonstrate that learning
related to tacit knowledge is often not captured in formal post-project
review reports (\citeproc{ref-goffin2011}{\textbf{goffin2011?}}), and
conventional mechanisms such as documents, blueprints, and procedures
fail because tacit knowledge is not easily codified
(\citeproc{ref-foos2006}{\textbf{foos2006?}}). Research across multiple
industries consistently shows that written reports and databases fail to
convey key learning from expert teams
(\citeproc{ref-goffin2010}{\textbf{goffin2010?}}), while experts often
lack the skills, motivation, or time to document their expertise, and
even when documentation is attempted, essential aspects are lost due to
lack of shared experience between experts and novices
(\citeproc{ref-rintala2006}{\textbf{rintala2006?}}).

\subsubsection{Inadequacy of Traditional
Approaches}\label{inadequacy-of-traditional-approaches}

The literature demonstrates that conventional knowledge management
approaches fail in healthcare contexts
(\citeproc{ref-mayo2016}{\textbf{mayo2016?}},\citeproc{ref-shahbaz2019}{\textbf{shahbaz2019?}}):

\begin{itemize}
\tightlist
\item
  Traditional knowledge transfer mechanisms show limited effectiveness
\item
  Organizations struggle to capture and maintain analytical expertise
\item
  Security concerns and employee resistance to change slow the pace of
  information system acceptance
  (\citeproc{ref-shahbaz2019}{\textbf{shahbaz2019?}})
\item
  Person-to-person knowledge transfer fails during rapid turnover cycles
\end{itemize}

\subsection{Integration of Evidence: Synthesis Across Three
Pillars}\label{integration-of-evidence-synthesis-across-three-pillars}

\subsubsection{Bridging Technical and Domain
Expertise}\label{bridging-technical-and-domain-expertise}

At its core, bridging technical and domain expertise serves a
fundamental patient care objective: enabling clinical professionals to
access and act on data that improves care quality. The convergence of
evidence from these three domains reveals compounding effects that the
three-pillar framework synthesizes. Natural language interfaces directly
address the technical barriers identified in the literature by
eliminating the need for SQL expertise while preserving the
sophisticated query capabilities required for healthcare data.

Low-code platforms and conversational AI represent complementary
approaches to reducing technical barriers in healthcare analytics.
Low-code platforms provide visual development environments that
accelerate application development and reduce coding requirements, while
conversational AI enables natural language interaction with data
systems. These approaches share core benefits: both democratize access
by enabling non-technical users to perform complex analyses previously
requiring data scientist intervention, both accelerate development
cycles by abstracting technical complexity, and both produce more
self-documenting systems where business logic is expressed in accessible
formats rather than specialized code. Evidence from low-code
implementations thus informs conversational AI adoption, as both address
the same fundamental barrier: the gap between clinical expertise and
technical capability.

\subsubsection{Knowledge Preservation Through Embedded
Systems}\label{knowledge-preservation-through-embedded-systems}

The literature suggests that effective knowledge preservation requires
active, embedded systems rather than passive documentation. When
organizations choose to implement AI-based platforms, these can serve as
organizational memory systems by:

\begin{itemize}
\tightlist
\item
  Capturing decision-making patterns through usage
\item
  Encoding best practices in accessible formats
\item
  Providing context-aware guidance to new users
\item
  Maintaining knowledge currency through continuous learning
\end{itemize}

These principles align with conversational AI approaches that embed
institutional knowledge within the AI model itself, making expertise
permanently accessible regardless of staff turnover.

\subsubsection{Empirical Support for Barrier-Reducing
Technologies}\label{empirical-support-for-barrier-reducing-technologies}

Academic research provides growing evidence for both conversational AI
and low-code approaches in healthcare, technologies that share the goal
of reducing technical barriers to data-driven decision making. A
foundational systematic review of AI conversational agents in healthcare
(\citeproc{ref-milneives2020}{\textbf{milneives2020?}}) established that
such systems reduce burden on healthcare resources and save providers'
time, though the review identified a need for more rigorous quantitative
validation. Subsequent RCT-based systematic reviews provide this
evidence: a meta-analysis of conversational agent interventions reported
mean task completion rates of 83\% (range 40-100\%) across healthcare
applications (\citeproc{ref-li2023}{\textbf{li2023?}}). Real-world
validation at scale comes from a study of conversational AI across nine
NHS mental health services involving 64,862 patients, demonstrating
reduced clinician assessment time, shorter patient wait times, and lower
dropout rates (\citeproc{ref-rollwage2023}{\textbf{rollwage2023?}}). On
the clinical AI side, Sezgin et al.
(\citeproc{ref-sezgin2022}{\textbf{sezgin2022?}}) demonstrated that
GPT-3-powered chatbots can reduce overhead at clinics, while Jiao et al.
(\citeproc{ref-jiao2023}{\textbf{jiao2023?}}) found AI adoption leads to
cost savings through improved service delivery and shorter
hospitalization lengths. Dai and Abramoff
(\citeproc{ref-dai2023}{\textbf{dai2023?}}) explain that AI generates
predictions affordably, enabling earlier care that potentially prevents
costly interventions.

Low-code implementations provide parallel evidence for the benefits of
barrier reduction. Berkshire Healthcare NHS Trust
(\citeproc{ref-berkshire2024}{\textbf{berkshire2024?}}) reports over
1,600 individuals creating solutions using Microsoft Power Platform. The
NHS program demonstrates that healthcare professionals without IT
expertise can use low-code tools to create custom solutions and apps,
streamlining operations and enabling data-driven decisions. This
evidence supports the broader principle that reducing technical
barriers, whether through visual development or natural language
interfaces, enables healthcare domain experts to leverage data directly.
A systematic literature review of 17 peer-reviewed papers identified
cost and time minimization as the most frequently discussed benefits of
low-code development, with healthcare among the primary implementation
domains (\citeproc{ref-elkamouchi2023}{\textbf{elkamouchi2023?}}).
Controlled experiments quantify these benefits: a comparative study of
traditional versus low-code development for a healthcare cognitive
rehabilitation system found low-code required 47.5 hours versus 888
hours for traditional development, representing a 94.63\% reduction in
effort (\citeproc{ref-aveiro2023}{\textbf{aveiro2023?}}).
Industry-sponsored research from Forrester
(\citeproc{ref-forrester2024}{\textbf{forrester2024?}}) projects 206\%
three-year ROI from low-code implementations; peer-reviewed studies
report similar findings, with healthcare institutions achieving 177\%
ROI over 36 months while reducing development time by 67\% and technical
resource requirements by 58\%
(\citeproc{ref-mogili2025}{\textbf{mogili2025?}}), and small healthcare
clinics achieving 250\% cumulative ROI over three years
(\citeproc{ref-pervaiz2025}{\textbf{pervaiz2025?}}).

Healthcare-specific studies show concrete benefits across both
approaches: Pennington
(\citeproc{ref-pennington2023}{\textbf{pennington2023?}}) found AI in
revenue cycle management accelerated payment cycles from 90 days to 40
days, while Atobatele et al.
(\citeproc{ref-atobatele2023}{\textbf{atobatele2023?}}) documented how
low-code platforms enable non-technical staff to build applications,
leading to efficiency gains. Rapid application development using
low-code characteristics enabled an mHealth app for COVID-19 remote care
that saved 2,822 hospital bed-days for 400 enrolled patients
(\citeproc{ref-tan2023}{\textbf{tan2023?}}). These findings collectively
demonstrate that technologies enabling non-technical users to interact
with complex systems, whether through visual interfaces or natural
language, produce measurable organizational benefits.

\subsection{Implications for Healthcare
Organizations}\label{implications-for-healthcare-organizations}

\subsubsection{Framework Alignment with Industry
Trajectories}\label{framework-alignment-with-industry-trajectories}

Applied to recent industry literature, the three-pillar framework
highlights how barrier-reducing technologies track with broader
healthcare analytics trajectories. The revised HIMSS AMAM model
(\citeproc{ref-himss2024}{\textbf{himss2024?}}) emphasizes AI readiness
and governance frameworks, and conversational interfaces for analytics
can be understood as one illustrative application of these themes: they
aim to democratize access to data while preserving organizational
controls, rather than constituting a prescriptive pathway to maturity
advancement.

\subsubsection{ROI Evidence Across Barrier-Reducing
Approaches}\label{roi-evidence-across-barrier-reducing-approaches}

Academic research documents multiple pathways to ROI for
barrier-reducing technologies in healthcare. Conversational AI
implementations show direct benefits: Jiao et al.
(\citeproc{ref-jiao2023}{\textbf{jiao2023?}}) found that AI-driven
efficiency gains, including shorter hospitalization lengths, translate
into financial and operational benefits for healthcare providers;
Pennington (\citeproc{ref-pennington2023}{\textbf{pennington2023?}})
documented that AI in revenue cycle management accelerated payment
cycles from 90 to 40 days, improving cash flow; and Sezgin et al.
(\citeproc{ref-sezgin2022}{\textbf{sezgin2022?}}) proposed chatbot
implementations that reduce clinic overhead.

Low-code platform ROI provides analogous evidence for the value of
technical barrier reduction. Industry-sponsored research from Forrester
(\citeproc{ref-forrester2024}{\textbf{forrester2024?}}) projects 206\%
three-year ROI from Power Platform implementations. Peer-reviewed
studies corroborate these findings: a systematic review identified cost
and time reduction as the most frequently discussed benefits across 17
studies (\citeproc{ref-elkamouchi2023}{\textbf{elkamouchi2023?}}),
healthcare institutions report 177\% ROI over 36 months with 67\% faster
development (\citeproc{ref-mogili2025}{\textbf{mogili2025?}}), and small
healthcare clinics document 250\% cumulative three-year ROI
(\citeproc{ref-pervaiz2025}{\textbf{pervaiz2025?}}). While low-code and
conversational AI differ in implementation approach, both generate
returns through the same mechanism: enabling domain experts to
accomplish tasks previously requiring specialized technical staff.
Market research supports continued investment in accessible analytics:
Precedence Research
(\citeproc{ref-precedence2024}{\textbf{precedence2024?}}) projects the
healthcare analytics market to grow from \$64.49 billion in 2025 to
\$369.66 billion by 2034 (21.41\% CAGR).

\subsubsection{Knowledge Preservation as Risk
Factor}\label{knowledge-preservation-as-risk-factor}

The literature emphasizes that institutional memory loss represents an
existential risk to healthcare analytics programs, particularly when
critical analytical practices remain tacit and concentrated in a small
number of experts. Within our three-pillar framework, this risk appears
as a compounding mechanism: workforce turnover erodes tacit expertise,
low analytics maturity limits organizations' ability to encode that
expertise, and technical barriers constrain efforts to make encoded
knowledge broadly accessible. Effective knowledge preservation therefore
requires mechanisms that transform tacit analytical knowledge into
encoded, shareable, and routinely accessible artifacts. This requirement
aligns with Nonaka's SECI model (Socialization, Externalization,
Combination, Internalization), which describes organizational knowledge
creation as a continuous dialogue between tacit and explicit knowledge
(\citeproc{ref-farnese2019}{\textbf{farnese2019?}}). Recent research
demonstrates that AI tools, including conversational interfaces, can
enhance all four SECI stages, particularly facilitating the
externalization process where tacit analytical knowledge becomes
explicit, queryable forms
(\citeproc{ref-zhang2025}{\textbf{zhang2025?}}). This theoretical
foundation supports embedding organizational knowledge in systems rather
than individuals, ensuring continuity despite workforce turnover.

\subsection{Gaps in Current
Literature}\label{gaps-in-current-literature}

Despite substantial evidence supporting conversational AI in healthcare
analytics, several research gaps persist:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Long-term outcomes}: Most studies examine 6-24 month
  implementations; multi-year impacts remain understudied
\item
  \textbf{Scalability across specialties}: Evidence primarily focuses on
  general acute care; specialty-specific applications need investigation
\item
  \textbf{Governance frameworks}: Limited research on optimal governance
  models for democratized analytics
\item
  \textbf{Training methodologies}: Best practices for transitioning from
  traditional to conversational analytics lack empirical validation
\item
  \textbf{Integration patterns}: Architectural guidance for
  incorporating conversational AI into existing healthcare IT ecosystems
  remains sparse
\item
  \textbf{Long-term productivity tracking}: While peer-reviewed studies
  now document immediate productivity gains (63\% self-service adoption
  increase, 37\% data retrieval time reduction, 10-30\% query completion
  time improvement (\citeproc{ref-yuan2019}{\textbf{yuan2019?}}),
  (\citeproc{ref-dadi2025}{\textbf{dadi2025?}}),
  (\citeproc{ref-shah2020}{\textbf{shah2020?}}),
  (\citeproc{ref-ipeirotis2025}{\textbf{ipeirotis2025?}})), longitudinal
  studies tracking sustained productivity improvements over multiple
  years remain limited
\item
  \textbf{Citizen developer productivity methodology}: No validated
  healthcare-specific instrument exists for measuring citizen developer
  productivity. While Berkshire NHS reports over 1,600 citizen
  developers (\citeproc{ref-berkshire2024}{\textbf{berkshire2024?}}),
  the methodology for quantifying their productivity contributions lacks
  standardization across studies
\item
  \textbf{AMAM-specific outcome evidence}: The HIMSS Analytics Maturity
  Assessment Model (AMAM) was released in October 2024; existing outcome
  studies linking maturity stages to patient outcomes use the older
  EMRAM (EHR adoption) model
  (\citeproc{ref-snowdon2024}{\textbf{snowdon2024?}},\citeproc{ref-snowdon2024a}{\textbf{snowdon2024a?}}).
  As of this review, AMAM-specific outcome studies remain very limited,
  providing only emerging evidence for analytics maturity (as distinct
  from EHR adoption) impact on outcomes
\end{enumerate}

\subsection{Why the Problem Persists}\label{why-the-problem-persists}

Despite clear evidence of healthcare's analytics challenges and
available technology, the problem remains unsolved. Analysis of market
dynamics reveals three structural barriers:

\subsubsection{Failed Standardization
Approaches}\label{failed-standardization-approaches}

Large-scale efforts to standardize healthcare data and analytics have
consistently encountered fundamental barriers. Academic research
identifies a persistent tension between achieving short-term
institutional solutions and pursuing long-term global interoperability,
with standardization complexity arising from diverse community interests
and technical issues
(\citeproc{ref-richesson2007}{\textbf{richesson2007?}}). Data
standardization faces three primary technological obstacles: metadata
uncertainties, data transfer challenges, and missing data, compounded by
legacy data collection methods that have created a ``patchwork'' of
inconsistent organizational practices
(\citeproc{ref-gal2019}{\textbf{gal2019?}}).

These challenges manifest in clinical practice through workflow
variability. Even within the same institution, clinical workflows vary
significantly, and transitions to standardized systems often cause
profound disruptions to existing processes
(\citeproc{ref-zheng2020}{\textbf{zheng2020?}}). At the institutional
level, data fragmentation across different organizations creates
barriers to linkage, access, and care continuity, while governance
issues including unclear responsibilities and weak collaboration
compound the problem
(\citeproc{ref-bogaert2021}{\textbf{bogaert2021?}}).

High-profile industry events illustrate these documented challenges. IBM
divested its Watson Health data and analytics assets to Francisco
Partners in 2022 (\citeproc{ref-ibm2022}{\textbf{ibm2022?}}), following
years of underperformance attributed to a fundamental mismatch between
AI capabilities and clinical reality: the technology encountered the
``messy reality'' of healthcare systems where machines learn from
structured data but physicians work with unstructured, complex clinical
information (\citeproc{ref-strickland2019}{\textbf{strickland2019?}}).
Academic analysis identified additional contributing factors including
suboptimal business performance (only breaking even), a restrictive
top-down commercialization strategy that limited market reach, and the
highly-regulated nature of healthcare creating barriers to AI deployment
(\citeproc{ref-yang2020}{\textbf{yang2020?}}). The Haven healthcare
venture (backed by Amazon, Berkshire Hathaway, and JPMorgan Chase)
disbanded in 2021 after three years
(\citeproc{ref-lavito2021}{\textbf{lavito2021?}}), with academic
analysis identifying multiple contributing factors: even the three
founding companies could not effectively share health-care cost data
with each other, the venture never employed more than 75 people
(limiting its ability to effect industry-wide change), and leadership
turnover destabilized organizational continuity
(\citeproc{ref-acchiardo2021}{\textbf{acchiardo2021?}}). Research on Big
Tech platform entry into healthcare positions both Watson Health and
Haven within a broader pattern of technology companies encountering
regulatory complexity and institutional resistance when attempting to
standardize fragmented healthcare systems
(\citeproc{ref-ozalp2022}{\textbf{ozalp2022?}}). These outcomes align
with the academic literature's findings: standardized solutions face
significant barriers when applied across institutions with unique data
definitions, business rules, and clinical workflows.

These observations represent documented market events; however,
establishing causal mechanisms between organizational strategies and
interoperability outcomes requires controlled empirical research beyond
this review's scope. The patterns noted here warrant further
investigation through rigorous organizational studies.

\subsubsection{Deployment Constraint
Mismatch}\label{deployment-constraint-mismatch}

Healthcare organizations increasingly require solutions functional in
secure, air-gapped environments due to regulatory requirements and data
governance policies. General-purpose cloud AI services cannot meet these
deployment constraints while simultaneously lacking the
institution-specific context necessary for accurate analytics. The
fundamental requirement that institutional knowledge must be captured,
preserved, and accessed within each organization's specific environment
cannot be addressed by standardized cloud offerings.

These dynamics explain why, despite technological capability, the
healthcare analytics maturity gap persists. Solutions must be designed
for institution-specific deployment rather than cross-organizational
standardization.

\section{Discussion}\label{discussion}

\subsection{Strengths of the Evidence
Base}\label{strengths-of-the-evidence-base}

The evidence base for the three-pillar framework presents several
strengths:

\subsubsection{Validated Benchmarking
Data}\label{validated-benchmarking-data}

The evidence base includes peer-reviewed benchmarking studies from top
venues (NEJM AI, NeurIPS, NAACL) that provide empirical validation of
LLM capabilities in healthcare contexts. Studies like MedAgentBench
(\citeproc{ref-medagentbench2024}{\textbf{medagentbench2024?}}) and
comprehensive medical LLM evaluations
(\citeproc{ref-wu2024a}{\textbf{wu2024a?}}) offer reproducible,
quantitative performance metrics.

\subsubsection{Real-World Implementation
Evidence}\label{real-world-implementation-evidence}

The Berkshire Healthcare NHS Trust case
(\citeproc{ref-berkshire2024}{\textbf{berkshire2024?}}) demonstrates
successful low-code adoption in healthcare, with over 1,600 citizen
developers creating solutions. This provides concrete evidence that
non-technical healthcare professionals can effectively use these
platforms.

\subsubsection{Reveals Interconnected
Challenges}\label{reveals-interconnected-challenges}

The framework illuminates how technical barriers, analytics maturity
constraints, and institutional memory loss compound each other,
explaining why single-pillar interventions often fail. This integrated
perspective enables healthcare organizations to understand why
addressing one challenge in isolation may not produce lasting
improvement.

\subsubsection{Strong Economic
Justification}\label{strong-economic-justification}

The financial evidence is compelling, with Forrester Research
(\citeproc{ref-forrester2024}{\textbf{forrester2024?}}) documenting
206\% three-year ROI from low-code implementations. Market growth
projections (\citeproc{ref-precedence2024}{\textbf{precedence2024?}})
showing the healthcare analytics market expanding from \$64.49B to
\$369.66B by 2034 indicate sustained investment demand.

\subsubsection{Honest Assessment of
Limitations}\label{honest-assessment-of-limitations}

The evidence base includes important caveats. Ziletti and D'Ambrosi
(\citeproc{ref-ziletti2024}{\textbf{ziletti2024?}}) note that ``current
language models are not yet sufficiently accurate for unsupervised
use,'' and benchmarking studies
(\citeproc{ref-wu2024a}{\textbf{wu2024a?}},\citeproc{ref-ang2004}{\textbf{ang2004?}})
show significant gaps between benchmark performance and clinical
readiness. This honest assessment enables appropriate implementation
strategies.

\subsection{Limitations and
Constraints}\label{limitations-and-constraints}

Despite strong evidence supporting conversational AI adoption, several
limitations must be acknowledged:

\subsubsection{Implementation
Complexity}\label{implementation-complexity}

Healthcare environments present unique complexity challenges including
regulatory requirements, legacy system integration, and change
management across diverse user populations. Implementation timelines
reflect this complexity, though low-code approaches compare favorably to
traditional analytics infrastructure projects. Healthcare and
pharmaceutical organizations face particularly acute legacy
modernization challenges, paralleling patterns documented in broader
enterprise software contexts
(\citeproc{ref-anthropic2025}{\textbf{anthropic2025?}}).

\subsubsection{Context-Specific Customization
Requirements}\label{context-specific-customization-requirements}

Healthcare organizations vary significantly in data structures, clinical
workflows, and analytical needs. Evidence suggests that successful
implementations require substantial customization to organizational
contexts, potentially limiting the applicability of standardized
approaches.

\subsubsection{Long-Term Outcome
Uncertainties}\label{long-term-outcome-uncertainties}

Most studies examine 6-24 month implementations. Questions remain about
long-term sustainability, user engagement over extended periods, and the
evolution of organizational capabilities beyond initial deployment
periods. The research gap analysis in the Literature Review identifies
this as a priority area for future investigation.

\subsubsection{Governance and Quality Assurance
Challenges}\label{governance-and-quality-assurance-challenges}

Democratizing analytics access creates new challenges in maintaining
data quality, analytical rigor, and clinical safety standards. While the
evidence shows reduced error rates with conversational AI, healthcare
organizations must develop new governance frameworks for managing
distributed analytical capabilities.

\subsubsection{Specialty-Specific Application
Gaps}\label{specialty-specific-application-gaps}

Evidence primarily focuses on general acute care settings. Applications
in specialized domains (oncology, cardiology, mental health) require
domain-specific validation and customization that may not generalize
from the existing evidence base.

\subsubsection{Methodological
Considerations}\label{methodological-considerations}

As a narrative review, this paper has methodological limitations
distinct from systematic reviews. The non-exhaustive literature search,
single-author synthesis, and post-hoc selection criteria may have
introduced selection or interpretation bias. No formal quality
assessment tool was applied to included studies. These limitations,
documented in detail in the Methodology section, should be considered
when interpreting findings. The transparency provided through explicit
documentation of search strategies, selection criteria, and synthesis
approach enables readers to assess potential biases and evaluate the
robustness of conclusions.

\subsection{Future Research
Directions}\label{future-research-directions}

The evidence review identifies several priority areas for future
investigation:

\subsubsection{Short-Term Research Priorities (\textless1
year)}\label{short-term-research-priorities-1-year}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Reference Implementation Validation}: Empirical validation of
  NL2SQL approaches using synthetic healthcare data (e.g., Synthea) in
  reproducible cloud environments, enabling benchmarking against
  established datasets (EHRSQL, MIMICSQL) without privacy constraints
\item
  \textbf{Schema Discovery for Healthcare Databases}: Research on
  automated primary/foreign key discovery algorithms applied to
  healthcare schemas, addressing the complexity of clinical data models
\item
  \textbf{Governance Framework Development}: Research on optimal
  governance models for democratized analytics
\end{enumerate}

\subsubsection{Medium-Term Research Priorities (1-2
years)}\label{medium-term-research-priorities-1-2-years}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Healthcare Terminology Integration}: Development of
  programmatic approaches for mapping natural language queries to
  standardized vocabularies (SNOMED CT, LOINC, RxNorm) within NL2SQL
  pipelines
\item
  \textbf{FHIR/OMOP Interoperability}: Research on reducing ETL burden
  for OMOP Common Data Model and FHIR transformations, enabling NL2SQL
  systems to operate across heterogeneous healthcare data standards
\item
  \textbf{Longitudinal Outcome Studies}: Multi-year implementations to
  assess sustained benefits and organizational evolution
\item
  \textbf{Comparative Effectiveness Research}: Head-to-head comparisons
  of different conversational AI approaches on healthcare-specific
  benchmarks
\end{enumerate}

\subsubsection{Long-Term Research Priorities (\textgreater2
years)}\label{long-term-research-priorities-2-years}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Organizational Transformation Studies}: Research on how
  conversational AI platforms reshape healthcare organizational
  capabilities
\item
  \textbf{Clinical Outcome Impact Assessment}: Studies linking improved
  analytics access to patient care outcomes
\item
  \textbf{Cross-Institution Knowledge Portals}: Investigation of
  federated approaches enabling knowledge sharing across healthcare
  organizations while maintaining privacy and security requirements
\end{enumerate}

\subsection{Illustrative Application: Knowledge Preservation
Mechanisms}\label{illustrative-application-knowledge-preservation-mechanisms}

To illustrate how the three-pillar framework might inform technology
design, we examine the validated query cycle concept introduced earlier.
This mechanism differs fundamentally from traditional knowledge
management approaches in healthcare. Traditional approaches rely on
documentation: analysts write procedures, create data dictionaries, and
maintain query libraries. However, documentation suffers from three
critical weaknesses: it becomes stale as systems evolve, it captures
procedural knowledge but not contextual judgment, and it requires active
maintenance that often lapses after staff transitions.

Validated query pairs address each weakness. First, validated pairs are
executable: they can be tested against current data to verify continued
correctness, unlike static documentation. Second, validated pairs
capture the complete mapping from business question to data retrieval
logic, embedding the contextual judgment that documentation typically
omits (why this join, why this filter, why this aggregation). Third,
validation happens at the point of use rather than as a separate
maintenance task: every confirmed query becomes a knowledge artifact
without additional documentation effort.

This mechanism also differs from traditional query logging or usage
analytics. Query logs capture what was asked, but not whether the answer
was correct. Validated query pairs capture expert confirmation that the
SQL correctly answers the business question. This distinction is
critical for institutional memory: organizations need to know not just
what queries were run, but which queries produced trusted, verified
answers.

Governance requirements for the validated query cycle include: defining
who can validate queries (domain expertise requirements), establishing
validation workflows (review processes for high-stakes queries),
managing query versioning (as schemas evolve), and implementing
retrieval policies (when to return exact matches versus inform new
generation). Organizations implementing conversational AI platforms
should design these governance structures before deployment rather than
retrofitting them after knowledge accumulation begins.

\subsubsection{Resolving the Validator Paradox: Knowledge Ratchet and
Standard
Work}\label{resolving-the-validator-paradox-knowledge-ratchet-and-standard-work}

A critical paradox emerges in the proposed solution: reliance on expert
validation in an environment defined by expert turnover. If the experts
are leaving, who validates the AI? To resolve this ``validator
paradox,'' validation must be reframed not as \emph{eternal truth} but
as the ``standard work'' of informatics, drawing on Lean management
principles (\citeproc{ref-alukal2006}{\textbf{alukal2006?}}).

In this model, a validated query represents the ``current best way'' to
perform an analysis. As Alukal and Manos
(\citeproc{ref-alukal2006}{\textbf{alukal2006?}}) establish, standard
work is the prerequisite for Kaizen (continuous improvement): without a
documented standard, there is no baseline to improve upon. The Validated
Query Cycle functions as an ``organizational knowledge ratchet''
(\citeproc{ref-rao2006}{\textbf{rao2006?}}). Even provisional validation
by mid-level analysts captures operational logic into a procedural
artifact. This prevents the ``sliding back to zero'' that occurs during
turnover, allowing the organization to maintain a performance baseline
that persists independent of individual tenure
(\citeproc{ref-hong2025}{\textbf{hong2025?}}). Rather than requiring a
permanent ``core nucleus'' of experts, the system accumulates knowledge
incrementally, using the structure of the validation process to buffer
against the disruptive effects of turnover.

\subsubsection{Comparative Analysis of Knowledge Preservation
Strategies}\label{comparative-analysis-of-knowledge-preservation-strategies}

Organizations have attempted to solve the institutional memory crisis
through various strategies. This review compares the proposed
conversational AI approach against established alternatives:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Code-Based Semantic Layers}: Traditional semantic layers
  (e.g., dbt, LookML) attempt to encode business logic in
  version-controlled repositories. However, research indicates these
  layers suffer from ``schema rot'' in healthcare environments where EMR
  data models change frequently (e.g., quarterly upgrades). The
  maintenance burden often exceeds the capacity of high-turnover teams,
  leading to misalignment between the layer and the underlying data
  (\citeproc{ref-mannapur2025}{\textbf{mannapur2025?}},\citeproc{ref-yupopa2005}{\textbf{yupopa2005?}}).
\item
  \textbf{Passive vs.~Active Capture}: Traditional knowledge management
  relies on passive capture (wikis, documentation) where users must stop
  working to document. Evidence suggests this negatively impacts
  participation and leads to inaccurate records due to cognitive load
  (\citeproc{ref-whittaker2008}{\textbf{whittaker2008?}}). In contrast,
  conversational interfaces represent active capture where the query
  itself is the documentation
  (\citeproc{ref-moore2018}{\textbf{moore2018?}}), integrating knowledge
  preservation directly into the analytical workflow.
\item
  \textbf{Governance vs.~Shadow IT}: Rigid, centralized models often
  drive analysts toward Shadow IT (extracting raw data to Excel) to
  achieve flexibility, defeating governance goals
  (\citeproc{ref-zimmermann2017}{\textbf{zimmermann2017?}}).
  Conversational interfaces offer a middle path: providing the
  flexibility of natural language exploration within the governance
  perimeter of the validated query cycle
  (\citeproc{ref-oliveira2023}{\textbf{oliveira2023?}}). This approach
  aligns with recent evidence from UC Davis Health, where establishing a
  centralized ``Health Data Oversight Committee'' and standardized
  definitions enabled the organization to advance from AMAM Stage 0 to
  Stage 6, supporting over 2,400 analytics products while weeding out
  biased AI models (\citeproc{ref-himss2025ucdavis}{5}). By decoupling
  data access from data definition, organizations can democratize the
  \emph{consumption} of analytics without democratizing the
  \emph{creation} of potentially flawed metrics.
\end{enumerate}

\subsubsection{Lifecycle Management: Continuous Analytic
Integration}\label{lifecycle-management-continuous-analytic-integration}

A validated SQL query is often treated as a static artifact, but in
healthcare, database schemas (Epic, Cerner, OMOP) change frequently,
breaking ``frozen'' code. To address ``Schema Drift,'' analytics must
adopt principles from software engineering: \textbf{Continuous Analytic
Integration}.

In this approach, Validated Query Pairs are managed not as wiki entries
but as software assets within a CI/CD pipeline. When the data warehouse
schema is updated (e.g., a quarterly EHR upgrade), the system
automatically re-runs the library of stored queries. Queries that fail
or return anomalous results are flagged for review. This transforms
``Institutional Memory'' from a stagnant repository into a living,
automated test suite that actively signals when organizational knowledge
has drifted from technical reality.

\subsection{Strategic Implications for Healthcare
Organizations}\label{strategic-implications-for-healthcare-organizations}

The evidence has implications for healthcare leaders considering
analytics strategy:

\subsubsection{Organizational Assessment Using the Three-Pillar
Framework}\label{organizational-assessment-using-the-three-pillar-framework}

The three-pillar framework provides a structured approach for
organizational self-assessment:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Analytics Maturity Assessment}: Where does the organization
  currently stand on the HIMSS AMAM scale? What capabilities are needed
  to advance?
\item
  \textbf{Workforce Knowledge Audit}: What tacit knowledge resides with
  individual staff members? How vulnerable is the organization to
  knowledge loss through turnover?
\item
  \textbf{Technical Barrier Inventory}: What technical skills are
  currently required for data access? Which clinical questions go
  unanswered due to technical barriers?
\end{enumerate}

\subsubsection{Three-Pillar Assessment
Rubric}\label{three-pillar-assessment-rubric}

The three-pillar framework enables organizational self-assessment to
determine readiness for and potential benefit from NL2SQL and
conversational AI interventions. Table 3 provides an evidence-based
rubric where each indicator anchors to reviewed literature.
Organizations scoring predominantly ``Higher Risk'' across pillars face
compounding challenges that NL2SQL platforms are specifically designed
to address: democratizing data access (Technical Barriers), preserving
institutional knowledge (Workforce Dynamics), and accelerating maturity
advancement (Analytics Maturity).

\textbf{Table 3: Three-Pillar Organizational Assessment Rubric}

\textbf{Analytics Maturity Indicators:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1803}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1967}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2131}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1639}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Indicator
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Lower Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Moderate Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Higher Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Evidence
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
HIMSS AMAM Stage & Stages 5-7: Predictive analytics, AI integration &
Stages 3-4: Integrated warehouse, standardized definitions & Stages 0-2:
Fragmented data, limited reporting &
(\citeproc{ref-himss2024}{\textbf{himss2024?}},\citeproc{ref-health2020}{\textbf{health2020?}}) \\
Self-service analytics & Widespread; clinical staff access data directly
& Partial; BI tools available but underutilized & None; all analytics
require IT intervention &
(\citeproc{ref-berkshire2024}{\textbf{berkshire2024?}},\citeproc{ref-wang2018}{\textbf{wang2018?}}) \\
AI/NL interface availability & Natural language query capability
deployed & Pilot programs or evaluation underway & No NL2SQL or
conversational analytics &
(\citeproc{ref-wang2020}{\textbf{wang2020?}},\citeproc{ref-ziletti2024}{\textbf{ziletti2024?}}) \\
\end{longtable}

\textbf{Workforce Dynamics Indicators:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1803}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1967}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2131}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1639}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Indicator
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Lower Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Moderate Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Higher Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Evidence
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
First-year Staff Turnover & \textless15\% & 15-30\% & \textgreater30\% &
(\citeproc{ref-nsi2025}{\textbf{nsi2025?}}) \\
Leadership Stability (CIO) & Tenure \textgreater{} 5 years & Tenure 3-5
years & Tenure \textless{} 3 years &
(\citeproc{ref-wittkieffer2024}{\textbf{wittkieffer2024?}}) \\
Knowledge concentration & Distributed expertise; documented processes &
Partial documentation; some cross-training & Critical expertise held by
≤3 individuals &
(\citeproc{ref-benbya2004}{\textbf{benbya2004?}},\citeproc{ref-richesson2007}{\textbf{richesson2007?}}) \\
Time-to-productivity & \textless6 months with structured onboarding &
6-18 months & \textgreater18 months (specialized health informatics
roles) &
(\citeproc{ref-ledikwe2013}{\textbf{ledikwe2013?}},\citeproc{ref-mantas2010}{\textbf{mantas2010?}},\citeproc{ref-musa2023}{\textbf{musa2023?}}) \\
Tacit knowledge capture & Expertise embedded in systems/AI & Partial
documentation exists & Person-dependent; undocumented tribal knowledge &
(\citeproc{ref-benbya2004}{\textbf{benbya2004?}}) \\
\end{longtable}

\textbf{Technical Barriers Indicators:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1803}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1967}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2131}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.1639}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Indicator
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Lower Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Moderate Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Higher Risk
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Evidence
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Data access requirements & Natural language or visual query interfaces &
IT queue for complex queries; basic self-service & SQL/technical
expertise required for all queries &
(\citeproc{ref-wang2018}{\textbf{wang2018?}},\citeproc{ref-bardsley2016}{\textbf{bardsley2016?}},\citeproc{ref-pesqueira2020}{\textbf{pesqueira2020?}}) \\
Interoperability status & Unified data platform; real-time integration &
Partial integration; some automated feeds & Fragmented systems; manual
reconciliation required &
(\citeproc{ref-gal2019}{\textbf{gal2019?}},\citeproc{ref-bogaert2021}{\textbf{bogaert2021?}}) \\
Skills gap severity & Sufficient analysts across departments &
Acknowledged deficit with mitigation plans & Critical shortage
preventing data utilization &
(\citeproc{ref-bardsley2016}{\textbf{bardsley2016?}},\citeproc{ref-pesqueira2020}{\textbf{pesqueira2020?}}) \\
\end{longtable}

\textbf{Multi-Pillar Convergence Assessment:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2917}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3750}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Organizational Profile
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Framework Assessment
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Implications for Analysis
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
All pillars Lower Risk & Continuous improvement stance & Monitor for
emerging challenges; single-pillar focus may suffice \\
1 pillar Higher Risk & Isolated challenge & Single-domain intervention
may address root cause; watch for spillover effects \\
2 pillars Higher Risk & Compounding effects present & Framework reveals
interconnections requiring multi-dimensional analysis \\
All 3 pillars Higher Risk & Self-reinforcing degradation cycle & All
three dimensions interact; comprehensive organizational assessment
warranted \\
\end{longtable}

The framework reveals why convergence matters: organizations facing
Higher Risk across multiple pillars experience compounding effects where
challenges in one domain exacerbate challenges in others. For example,
technical barriers that prevent knowledge capture interact with
workforce turnover to accelerate institutional memory loss, which in
turn degrades analytics maturity. This multi-pillar perspective explains
why single-domain interventions often produce limited results.

\subsubsection{Illustrative Application: Implementation
Patterns}\label{illustrative-application-implementation-patterns}

When organizations choose to apply the framework and evaluate
barrier-reducing technologies for potential adoption, implementation
evidence suggests several factors influence outcomes:

\begin{itemize}
\tightlist
\item
  \textbf{Governance Framework Development}: New policies and procedures
  for democratized analytics
\item
  \textbf{Change Management}: Training and support programs to ensure
  user adoption
\item
  \textbf{Phased Deployment}: Gradual rollout beginning with
  analytics-savvy early adopters
\item
  \textbf{Human Oversight}: Current NL2SQL limitations require
  maintaining human review of AI-generated outputs
  (\citeproc{ref-ziletti2024}{\textbf{ziletti2024?}})
\end{itemize}

\section{Conclusion}\label{conclusion}

This narrative review synthesized evidence across three interconnected
domains: natural language to SQL generation, healthcare analytics
maturity, and workforce-driven institutional memory loss. The primary
contribution is a three-pillar analytical framework that reveals how
these challenges interconnect and compound each other.

\subsection{What the Framework
Reveals}\label{what-the-framework-reveals}

The three-pillar framework illuminates patterns that single-domain
analyses miss:

\begin{itemize}
\tightlist
\item
  \textbf{Analytics maturity gaps} leave clinical decisions unsupported
  by available data, and low maturity correlates with higher workforce
  turnover as staff leave organizations where they cannot accomplish
  their goals
\item
  \textbf{Workforce turnover} (\textasciitilde34\% implied annual rate
  for new healthcare IT staff as of 2004
  (\citeproc{ref-ang2004}{\textbf{ang2004?}})) causes institutional
  memory loss that further degrades analytics capabilities, creating a
  reinforcing cycle
\item
  \textbf{Technical barriers} prevent organizations from capturing and
  preserving analytical knowledge, blocking recovery from either
  maturity gaps or turnover impacts
\end{itemize}

These interconnections explain why addressing any single pillar in
isolation often fails: improvements in one area erode when the
compounding effects from other pillars continue. The framework provides
a structured lens for organizational self-assessment.

\subsection{Summary of Contributions}\label{summary-of-contributions}

This narrative review contributes to healthcare informatics scholarship
through:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Three-Pillar Analytical Framework} (Primary Contribution): The
  framework synthesizes previously disconnected evidence from healthcare
  analytics maturity, workforce management, and natural language
  processing research, revealing how these challenges interconnect and
  compound each other: low maturity accelerates turnover, turnover
  degrades maturity, and technical barriers prevent recovery from
  either.
\item
  \textbf{Evidence Synthesis}: We consolidate current evidence on each
  pillar, providing healthcare organizations with a comprehensive view
  of analytics maturity benchmarks, workforce turnover impacts, and
  NL2SQL technical capabilities in a single resource.
\item
  \textbf{Illustrative Application}: By applying established knowledge
  portal theory
  (\citeproc{ref-benbya2004}{\textbf{benbya2004?}},\citeproc{ref-richesson2007}{\textbf{richesson2007?}}),
  we describe the validated query cycle as one example of how the
  framework might inform technology design for institutional memory
  preservation.
\end{enumerate}

\subsection{Key Findings}\label{key-findings}

This review of academic and industry sources establishes several
critical findings:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Technical Progress with Limitations}: Natural language to SQL
  technologies have advanced significantly, with healthcare-specific
  benchmarks
  (\citeproc{ref-lee2023}{\textbf{lee2023?}},\citeproc{ref-wang2020}{\textbf{wang2020?}})
  demonstrating substantial progress in clinical NL2SQL tasks. However,
  current models are ``not yet sufficiently accurate for unsupervised
  use'' in clinical settings
  (\citeproc{ref-ziletti2024}{\textbf{ziletti2024?}}), requiring human
  oversight.
\item
  \textbf{Organizational Need}: Healthcare analytics maturity remains an
  ongoing challenge, with the revised HIMSS AMAM model
  (\citeproc{ref-himss2024}{\textbf{himss2024?}}) emphasizing the need
  for AI readiness and governance frameworks. Most organizations
  struggle to advance beyond basic reporting levels.
\item
  \textbf{Workforce Impact}: Healthcare IT staff new-hire turnover was
  implied at \textasciitilde34\% in 2004
  (\citeproc{ref-ang2004}{\textbf{ang2004?}}), the highest instability
  among IT sectors at that time, and workforce challenges persist today
  (\citeproc{ref-american2023}{\textbf{american2023?}}). Knowledge loss
  costs can reach three times annual salary budgets
  (\citeproc{ref-massingham2018}{\textbf{massingham2018?}}), creating
  need for knowledge preservation approaches.
\item
  \textbf{Implementation Evidence}: Real-world implementations like
  Berkshire Healthcare NHS Trust
  (\citeproc{ref-berkshire2024}{\textbf{berkshire2024?}}) demonstrate
  that low-code platforms can enable over 1,600 citizen developers in
  healthcare settings, with academic research documenting significant
  efficiency improvements and cost reductions
  (\citeproc{ref-sezgin2022}{\textbf{sezgin2022?}},\citeproc{ref-jiao2023}{\textbf{jiao2023?}}).
\end{enumerate}

\subsection{Implications for Organizational
Assessment}\label{implications-for-organizational-assessment}

The evidence synthesis suggests healthcare organizations face decisions
that cannot be reduced to simple adoption/rejection binaries. Applying
\emph{primum non nocere} comprehensively requires organizational leaders
to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Assess current harm exposure}: Quantify institutional memory
  loss from turnover, measure time-to-insight for clinical questions,
  and evaluate analytics capability gaps against organizational needs
\item
  \textbf{Evaluate intervention risks}: Consider NL2SQL accuracy
  limitations (``not yet sufficiently accurate for unsupervised use''
  (\citeproc{ref-ziletti2024}{\textbf{ziletti2024?}})), governance
  requirements, and implementation complexity
\item
  \textbf{Apply the three-pillar framework}: Use the analytics maturity,
  workforce turnover, and technical barrier dimensions to structure
  organizational assessment and prioritization
\end{enumerate}

Throughout this assessment, quality patient care must remain the primary
metric. Operational efficiency, cost savings, and technical capabilities
are valuable only insofar as they advance healthcare's fundamental
mission.

This framework acknowledges that optimal decisions will vary by
organizational context. Healthcare systems with stable analytics teams
and mature data infrastructure face different risk profiles than those
experiencing rapid turnover and limited analytics capabilities. The
evidence does not prescribe universal solutions but provides structured
approaches for context-specific evaluation.

\subsection{Closing Reflection}\label{closing-reflection}

\emph{Primum non nocere} ultimately requires healthcare organizations to
make evidence-based judgments about both action and inaction. This
review contributes a three-pillar analytical framework to support those
judgments, synthesizing evidence on analytics maturity, workforce
dynamics, and technical capabilities.

The evidence does not prescribe universal adoption of any technology.
Rather, it establishes the scope and interconnection of challenges that
organizations must address through whatever means align with their
specific contexts, capabilities, and risk tolerances. The ongoing harms
documented in this review (institutional memory loss, analytics
capability gaps, and technical barriers to data access) merit the same
careful consideration as the risks of new technology adoption.

Healthcare's commitment to avoiding harm is best served by
evidence-based evaluation that considers all dimensions of potential
benefit and risk. The three-pillar framework offers one structured
approach for conducting such evaluations.

\section{Acknowledgments}\label{acknowledgments}

The author (S.T.H.) takes full responsibility for the final content,
conducted the research, and verified all claims and citations. Claude
Code (Claude Opus 4.5, Anthropic) assisted with manuscript editing and
refinement.

\section{Author Contributions}\label{author-contributions}

S.T.H. conceived the research, conducted the literature review, and
wrote the manuscript.

\section{Conflicts of Interest}\label{conflicts-of-interest}

The author declares the following competing interests: Samuel T Harrold
is a contract product advisor at Yuimedi, Inc., which develops
healthcare analytics software including conversational AI platforms
relevant to this review's subject matter. The author is also employed as
a Data Scientist at Indiana University Health. This paper presents an
analytical framework derived from published literature and does not
evaluate or recommend specific commercial products, including those of
the author's affiliated organizations. The views expressed are the
author's own and do not represent the official positions of Indiana
University Health or Yuimedi, Inc.

\section{Data Availability}\label{data-availability}

This is a narrative review synthesizing existing literature. No primary
datasets were generated or analyzed. All data cited are from publicly
available peer-reviewed publications and industry reports, referenced in
the bibliography. The literature search methodology and source selection
criteria are documented in the Methodology section.

\section{Code Availability}\label{code-availability}

Not applicable. No custom code was developed for this research.

\section{Funding}\label{funding}

Yuimedi provided funding for the author's time writing and researching
this manuscript.

\section{Abbreviations}\label{abbreviations}

AACODS: Authority, Accuracy, Coverage, Objectivity, Date, Significance
ACO: Accountable Care Organization AI: Artificial Intelligence AMAM:
Analytics Maturity Assessment Model CPT: Current Procedural Terminology
DAMAF: Data Analytics Maturity Assessment Framework DIKW:
Data-Information-Knowledge-Wisdom EHR: Electronic Health Record EMRAM:
Electronic Medical Record Adoption Model HDQM2: Healthcare Data Quality
Maturity Model HIMSS: Healthcare Information Management Systems Society
ICD: International Classification of Diseases IT: Information Technology
LLM: Large Language Model NL2SQL: Natural Language to SQL RAG:
Retrieval-Augmented Generation SQL: Structured Query Language

\section{Appendices}\label{appendices}

\subsection{Appendix A: Healthcare Analytics
Glossary}\label{appendix-a-healthcare-analytics-glossary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
AMAM & Analytics Maturity Assessment Model - HIMSS standard for
measuring healthcare analytics capabilities \\
Clinical Terminology & Standardized vocabularies including ICD-10, CPT,
SNOMED, and RxNorm used in healthcare data \\
Conversational AI & Artificial intelligence systems that enable natural
language interaction for complex tasks \\
EHR & Electronic Health Record - digital version of patient medical
records \\
HIMSS & Healthcare Information and Management Systems Society -
healthcare IT standards organization \\
Institutional Memory & Collective organizational knowledge, expertise,
and practices that enable effectiveness \\
NL2SQL & Natural Language to SQL - technology that converts
spoken/written queries into database commands \\
Population Health & Analytics focused on health outcomes of groups of
individuals rather than individual patients \\
RAG & Retrieval Augmented Generation - AI approach combining information
retrieval with text generation \\
\end{longtable}

\subsection{Appendix B: HIMSS Analytics Maturity Assessment Model (AMAM)
Stages}\label{appendix-b-himss-analytics-maturity-assessment-model-amam-stages}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1591}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1364}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2955}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.4091}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Stage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Name
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Capabilities
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Stage 0 & Data Collection & Basic data capture without integration &
Manual data entry, paper records \\
Stage 1 & Data Verification & Automated data validation and error
checking & Basic quality controls, automated checks \\
Stage 2 & Data Utilization & Standard reporting and basic analytics &
Automated reports, dashboard creation \\
Stage 3 & Automated Decision Support & Rule-based clinical and
operational support & Clinical alerts, automated protocols \\
Stage 4 & Population Health Analytics & Population-level analysis and
intervention & Cohort identification, risk stratification \\
Stage 5 & Predictive Analytics & Statistical modeling and predictive
capabilities & Predictive models, trend analysis \\
Stage 6 & Cognitive Analytics & Machine learning and AI integration &
Advanced AI, pattern recognition \\
Stage 7 & Precision Medicine & Personalized treatment and genomic
integration & Personalized care, genomic analytics \\
\end{longtable}

\subsection{Appendix C: Healthcare NL2SQL Query
Examples}\label{appendix-c-healthcare-nl2sql-query-examples}

\subsubsection{Patient Population
Analysis}\label{patient-population-analysis}

\textbf{Natural Language}: ``Show me all diabetic patients over 65 who
had an HbA1c test in the last 6 months''

\textbf{Generated SQL}:

\begin{lstlisting}[language=SQL]
SELECT p.patient_id, p.age, l.test_date, l.result_value
FROM patients p
JOIN lab_results l ON p.patient_id = l.patient_id
JOIN diagnoses d ON p.patient_id = d.patient_id
WHERE d.icd10_code LIKE 'E11%'  -- Type 2 Diabetes
  AND p.age > 65
  AND l.test_name = 'HbA1c'
  AND l.test_date >= DATE_SUB(CURRENT_DATE, INTERVAL 6 MONTH)
\end{lstlisting}

\subsubsection{Complex Clinical Cohort: Heart Failure Readmission
Risk}\label{complex-clinical-cohort-heart-failure-readmission-risk}

\textbf{Natural Language}: ``Identify patients discharged with Heart
Failure in 2024 who had a readmission within 30 days, excluding those
discharged to hospice. For each, calculate their max creatinine levels
during the index stay.''

\textbf{Generated SQL}:

\begin{lstlisting}[language=SQL]
WITH IndexAdmissions AS (
    -- Identify index admissions for Heart Failure
    SELECT
        a.admission_id,
        a.patient_id,
        a.discharge_date,
        a.discharge_disposition
    FROM admissions a
    JOIN diagnoses d ON a.admission_id = d.admission_id
    WHERE d.icd10_code LIKE 'I50%'          -- Heart Failure codes
      AND a.discharge_date BETWEEN '2024-01-01' AND '2024-12-31'
      AND a.discharge_disposition != 'HOSPICE' -- Exclusion Criteria
),
Readmissions AS (
    -- Find readmissions within 30 days
    SELECT
        i.patient_id,
        i.admission_id AS index_admission_id,
        r.admission_date AS readmission_date,
        DATEDIFF(r.admission_date, i.discharge_date) AS days_to_readmit
    FROM IndexAdmissions i
    JOIN admissions r ON i.patient_id = r.patient_id
    WHERE r.admission_date > i.discharge_date
      AND r.admission_date <= DATE_ADD(i.discharge_date, INTERVAL 30 DAY)
)
-- Final Output: Cohort with Max Creatinine
SELECT
    r.patient_id,
    r.index_admission_id,
    r.days_to_readmit,
    MAX(CASE
        WHEN l.unit = 'mg/dL' THEN l.val_num
        WHEN l.unit = 'mmol/L' THEN l.val_num / 88.4  -- Value Normalization
        ELSE NULL
    END) as max_creatinine_mgdl
FROM Readmissions r
JOIN lab_events l ON r.index_admission_id = l.admission_id
WHERE l.itemid IN (50912, 50913) -- Creatinine lab codes
GROUP BY r.patient_id, r.index_admission_id, r.days_to_readmit;
\end{lstlisting}

\subsubsection{Quality Metrics}\label{quality-metrics}

\textbf{Natural Language}: ``How many patients were readmitted within 30
days of discharge for heart failure?''

\textbf{Generated SQL}:

\begin{lstlisting}[language=SQL]
SELECT COUNT(DISTINCT r.patient_id) as readmission_count
FROM (
  SELECT a1.patient_id, a1.discharge_date, a2.admission_date
  FROM admissions a1
  JOIN admissions a2 ON a1.patient_id = a2.patient_id
  JOIN diagnoses d ON a2.admission_id = d.admission_id
  WHERE d.icd10_code LIKE 'I50%'  -- Heart failure
    AND a2.admission_date BETWEEN a1.discharge_date AND DATE_ADD(a1.discharge_date, INTERVAL 30 DAY)
    AND a1.admission_id != a2.admission_id
) r
\end{lstlisting}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{This work is licensed under a Creative Commons Attribution 4.0
International License.}

\emph{Correspondence: samuel.harrold@yuimedi.com}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\bibitem[\citeproctext]{ref-tgh2025}
\CSLLeftMargin{1. }%
\CSLRightInline{Tampa General Hospital. {Tampa General Hospital Awarded
Highest Designation in Analytics by HIMSS} {[}Internet{]}. 2025.
Available from:
\url{https://www.tgh.org/news/tgh-press-releases/2025/june/tampa-general-hospital-awarded-highest-designation-analytics-himss}}

\bibitem[\citeproctext]{ref-cmuh2025}
\CSLLeftMargin{2. }%
\CSLRightInline{China Medical University Hospital. {Taiwan's First
Hospital to Achieve AMAM Stage 7 Certification!} {[}Internet{]}. PR
Newswire; 2025. Available from:
\url{https://www.prnewswire.com/news-releases/taiwans-first-hospital-to-achieve-amam-stage-7-certification-302390824.html}}

\bibitem[\citeproctext]{ref-himss2024apac}
\CSLLeftMargin{3. }%
\CSLRightInline{Healthcare IT News. {At HIMSS24 APAC, the Adoption Model
for Analytics Maturity gets facelift} {[}Internet{]}. 2024. Available
from:
\url{https://www.healthcareitnews.com/news/asia/himss24-apac-adoption-model-analytics-maturity-gets-facelift}}

\bibitem[\citeproctext]{ref-ksa2024}
\CSLLeftMargin{4. }%
\CSLRightInline{Medical Buyer. {2 medical groups in Saudi Arabia achieve
stage 7 digital maturity} {[}Internet{]}. 2024. Available from:
\url{https://medicalbuyer.co.in/2-medical-groups-in-saudi-arabia-achieve-stage-7-digital-maturity/}}

\bibitem[\citeproctext]{ref-himss2025ucdavis}
\CSLLeftMargin{5. }%
\CSLRightInline{HIMSS. {UC Davis Health: From Stage 0 to AI Heroes}
{[}Internet{]}. Healthcare Information; Management Systems Society;
2025. Available from:
\url{https://pages.himss.org/LP-HA-Case-Study-UC-Davis.html}}

\end{CSLReferences}

\end{document}
